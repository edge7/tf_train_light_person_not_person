{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "SAVED_MODEL_DIR = \"person_detection_saved_model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "model_fitted = tf.keras.models.load_model(\n",
    "    'model.h5', custom_objects=None, compile=False,\n",
    "    options=None\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def convert_into_flite(input_dir, output_name):\n",
    "    # Convert the model\n",
    "    converter = tf.lite.TFLiteConverter.from_saved_model(input_dir) # path to the SavedModel directory\n",
    "    converter.target_spec.supported_ops = [\n",
    "        tf.lite.OpsSet.TFLITE_BUILTINS  # enable ONLY TensorFlow Lite ops.\n",
    "    ]\n",
    "    tflite_model = converter.convert()\n",
    "\n",
    "    # Save the model.\n",
    "    with open(output_name, 'wb') as f:\n",
    "        f.write(tflite_model)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Convert into Flite, no quantization"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-18 20:54:24.901099: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:362] Ignored output_format.\n",
      "2023-03-18 20:54:24.901127: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:365] Ignored drop_control_dependency.\n",
      "2023-03-18 20:54:24.901258: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: person_detection_saved_model\n",
      "2023-03-18 20:54:24.905597: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }\n",
      "2023-03-18 20:54:24.905622: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: person_detection_saved_model\n",
      "2023-03-18 20:54:24.917329: I tensorflow/cc/saved_model/loader.cc:229] Restoring SavedModel bundle.\n",
      "2023-03-18 20:54:24.984662: I tensorflow/cc/saved_model/loader.cc:213] Running initialization op on SavedModel bundle at path: person_detection_saved_model\n",
      "2023-03-18 20:54:25.003889: I tensorflow/cc/saved_model/loader.cc:305] SavedModel load for tags { serve }; Status: success: OK. Took 102631 microseconds.\n"
     ]
    }
   ],
   "source": [
    "convert_into_flite(SAVED_MODEL_DIR, \"person_detection.tflite\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "SIZE = (256, 256)\n",
    "DATA_ROOT_FOLDER = \"/media/edge7/TOSHIBA EXT/\"  # Modify this as needed, you should have this variable set in get_dataset.ipynb, use the same\n",
    "DATA_IS_IN = os.path.join(DATA_ROOT_FOLDER, 'data')\n",
    "PERSON_FILES = os.path.join(DATA_IS_IN, 'person')\n",
    "NO_PERSON_FILES = os.path.join(DATA_IS_IN, 'notperson')\n",
    "all_files_train_p = [os.path.join( DATA_IS_IN, 'person', x) for x in os.listdir(PERSON_FILES)]\n",
    "all_files_train_np = [os.path.join( DATA_IS_IN, 'notperson', x) for x in os.listdir(NO_PERSON_FILES)]\n",
    "all_files = all_files_train_p + all_files_train_np\n",
    "\n",
    "def load_grayscale_images(limit=-1):\n",
    "    counter = 0\n",
    "    for path in all_files:\n",
    "        if counter > limit != -1:\n",
    "            break\n",
    "        counter +=1\n",
    "        image = Image.open(path)\n",
    "        image = np.array(image.resize(SIZE, resample=Image.BILINEAR))\n",
    "        if image.ndim == 3 and image.shape[2] == 4:\n",
    "            image = image[..., :3]  # Remove the alpha channel\n",
    "\n",
    "        if image.ndim == 3:\n",
    "            image = np.dot(image[...,:3], [0.2989, 0.5870, 0.1140]) # To gray scale\n",
    "        image = image / 255.0\n",
    "        image = tf.expand_dims(image, axis=-1)  # Add channel dimension\n",
    "        image = tf.expand_dims(image, axis=0)\n",
    "        image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "        yield [image]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "\n",
    "def convert_tf_lite_integer_only(input_dir, output_name):\n",
    "    # Create TFLiteConverter object and set optimizations\n",
    "    converter = tf.lite.TFLiteConverter.from_saved_model(input_dir)\n",
    "    # Set representative dataset\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    converter.representative_dataset = load_grayscale_images\n",
    "    tflite_quant_model = converter.convert()\n",
    "    # Save the model.\n",
    "    with open(output_name, 'wb') as f:\n",
    "        f.write(tflite_quant_model)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-18 20:54:25.726814: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:362] Ignored output_format.\n",
      "2023-03-18 20:54:25.726837: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:365] Ignored drop_control_dependency.\n",
      "2023-03-18 20:54:25.726952: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: person_detection_saved_model\n",
      "2023-03-18 20:54:25.731514: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }\n",
      "2023-03-18 20:54:25.731533: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: person_detection_saved_model\n",
      "2023-03-18 20:54:25.744228: I tensorflow/cc/saved_model/loader.cc:229] Restoring SavedModel bundle.\n",
      "2023-03-18 20:54:25.805746: I tensorflow/cc/saved_model/loader.cc:213] Running initialization op on SavedModel bundle at path: person_detection_saved_model\n",
      "2023-03-18 20:54:25.824683: I tensorflow/cc/saved_model/loader.cc:305] SavedModel load for tags { serve }; Status: success: OK. Took 97730 microseconds.\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: FLOAT32, output_inference_type: FLOAT32\n"
     ]
    }
   ],
   "source": [
    "convert_tf_lite_integer_only(SAVED_MODEL_DIR, \"person_detection_quantized.tflite\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Show difference, in tensor details, between quantized and not quantized model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'serving_default_input_2:0', 'index': 0, 'shape': array([  1, 256, 256,   1], dtype=int32), 'shape_signature': array([ -1, 256, 256,   1], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}] [{'name': 'StatefulPartitionedCall:0', 'index': 41, 'shape': array([1, 1], dtype=int32), 'shape_signature': array([-1,  1], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
      "tensor details\n",
      "[{'name': 'serving_default_input_2:0', 'index': 0, 'shape': array([  1, 256, 256,   1], dtype=int32), 'shape_signature': array([ -1, 256, 256,   1], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'model_1/global_average_pooling2d_1/Mean/reduction_indices', 'index': 1, 'shape': array([2], dtype=int32), 'shape_signature': array([2], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'model_1/dense_1/BiasAdd/ReadVariableOp', 'index': 2, 'shape': array([1], dtype=int32), 'shape_signature': array([1], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (1.315961253567366e-05, 0), 'quantization_parameters': {'scales': array([1.31596125e-05], dtype=float32), 'zero_points': array([0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'model_1/dense_1/MatMul', 'index': 3, 'shape': array([  1, 512], dtype=int32), 'shape_signature': array([  1, 512], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.002849585609510541, 0), 'quantization_parameters': {'scales': array([0.00284959], dtype=float32), 'zero_points': array([0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'model_1/re_lu_10/Relu;model_1/batch_normalization_10/FusedBatchNormV3;model_1/conv2d_5/BiasAdd/ReadVariableOp;model_1/conv2d_5/BiasAdd;model_1/conv2d_5/Conv2D', 'index': 4, 'shape': array([512], dtype=int32), 'shape_signature': array([512], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([8.07815013e-05, 9.30358583e-05, 1.90842533e-04, 1.64173602e-04,\n",
      "       1.41228375e-04, 2.05224307e-04, 2.31813639e-04, 8.32484584e-05,\n",
      "       1.90890714e-04, 1.78521383e-04, 1.60008713e-04, 1.64655896e-04,\n",
      "       1.74892019e-04, 2.22661474e-04, 1.77779992e-04, 1.43904414e-04,\n",
      "       2.01009330e-04, 1.96541747e-04, 2.13361505e-04, 2.25970070e-04,\n",
      "       1.53736604e-04, 1.79033625e-04, 1.65047881e-04, 1.79901544e-04,\n",
      "       1.69750245e-04, 1.60734882e-04, 2.17593493e-04, 2.08558704e-04,\n",
      "       1.46251492e-04, 1.75202789e-04, 1.68745712e-04, 2.12844374e-04,\n",
      "       1.08338900e-04, 2.03790027e-04, 1.53792687e-04, 1.51657412e-04,\n",
      "       1.75528039e-04, 1.76351998e-04, 1.95785658e-04, 1.97896064e-04,\n",
      "       1.69279956e-04, 2.15218315e-04, 2.69083685e-04, 1.47020037e-04,\n",
      "       1.50000094e-04, 2.67786818e-04, 8.85858753e-05, 1.54891910e-04,\n",
      "       2.46374519e-04, 1.74108602e-04, 1.64798097e-04, 1.67551319e-04,\n",
      "       7.34969653e-05, 1.61566044e-04, 1.75315639e-04, 1.38045463e-04,\n",
      "       2.42967188e-04, 2.65382609e-04, 1.60969925e-04, 1.72238273e-04,\n",
      "       1.99399990e-04, 1.81526571e-04, 2.10775441e-04, 1.61460775e-04,\n",
      "       1.52145614e-04, 1.83532276e-04, 2.13434440e-04, 1.39568991e-04,\n",
      "       2.09174017e-04, 1.97233298e-04, 1.94243446e-04, 1.66404076e-04,\n",
      "       1.94697175e-04, 1.58209150e-04, 1.62978453e-04, 1.47290120e-04,\n",
      "       1.98788475e-04, 2.20024915e-04, 1.77750626e-04, 1.66378610e-04,\n",
      "       1.70118743e-04, 1.73615845e-04, 1.55438902e-04, 2.18179150e-04,\n",
      "       1.85477955e-04, 2.99148873e-04, 1.28058688e-04, 2.07044999e-04,\n",
      "       1.76003043e-04, 1.91584884e-04, 2.37994900e-04, 1.68315790e-04,\n",
      "       2.42356211e-04, 9.48087036e-05, 1.69570048e-04, 1.53942863e-04,\n",
      "       2.06289755e-04, 1.95205415e-04, 1.80755320e-04, 2.94681173e-04,\n",
      "       1.61406933e-04, 2.05250049e-04, 1.77860813e-04, 1.03750004e-04,\n",
      "       1.78275019e-04, 1.81287396e-04, 2.49519246e-04, 2.04565338e-04,\n",
      "       1.83831013e-04, 1.64755824e-04, 1.68333005e-04, 1.44392761e-04,\n",
      "       1.51339278e-04, 1.81235911e-04, 1.56065289e-04, 2.09260426e-04,\n",
      "       1.94293738e-04, 1.62985627e-04, 2.07722333e-04, 1.73639506e-04,\n",
      "       1.83206692e-04, 7.59920731e-05, 1.89141865e-04, 1.56563226e-04,\n",
      "       1.98459762e-04, 1.45399856e-04, 1.82297605e-04, 1.91350278e-04,\n",
      "       1.13154492e-04, 1.69079547e-04, 2.16287372e-04, 1.77459835e-04,\n",
      "       2.26559336e-04, 8.08140394e-05, 1.64244848e-04, 1.68611819e-04,\n",
      "       1.77357913e-04, 1.72640721e-04, 1.37825977e-04, 2.10313781e-04,\n",
      "       1.81537791e-04, 1.47446932e-04, 1.76156886e-04, 1.54874666e-04,\n",
      "       1.27060019e-04, 1.17930569e-04, 1.44695019e-04, 1.58549432e-04,\n",
      "       2.05290999e-04, 1.84451783e-04, 1.77490219e-04, 2.07294841e-04,\n",
      "       1.90452745e-04, 1.69593288e-04, 1.37774638e-04, 1.83503274e-04,\n",
      "       1.71503081e-04, 1.35038805e-04, 1.78837057e-04, 2.34225401e-04,\n",
      "       1.38037372e-04, 1.56673050e-04, 2.01872608e-04, 1.85009878e-04,\n",
      "       1.81612748e-04, 1.60510754e-04, 1.62264187e-04, 1.38566858e-04,\n",
      "       2.15787994e-04, 1.46633960e-04, 1.72849366e-04, 1.65842182e-04,\n",
      "       2.13067382e-04, 1.80253744e-04, 1.99058442e-04, 1.76166228e-04,\n",
      "       1.82130141e-04, 1.64501020e-04, 1.63724166e-04, 1.99682123e-04,\n",
      "       2.21125112e-04, 1.57988936e-04, 1.79173468e-04, 1.71116641e-04,\n",
      "       1.46881430e-04, 1.65674181e-04, 2.05115561e-04, 1.68061626e-04,\n",
      "       2.26999735e-04, 1.56488459e-04, 1.89112383e-04, 1.68616607e-04,\n",
      "       1.78099144e-04, 1.58594354e-04, 2.06491226e-04, 1.70471103e-04,\n",
      "       1.55450500e-04, 1.55799979e-04, 1.46743332e-04, 1.68512692e-04,\n",
      "       1.68192098e-04, 2.23402429e-04, 1.69213788e-04, 1.97225803e-04,\n",
      "       1.42237885e-04, 2.01494753e-04, 1.60271986e-04, 2.18767556e-04,\n",
      "       1.75932262e-04, 2.05506964e-04, 1.93697750e-04, 1.61773976e-04,\n",
      "       1.54865003e-04, 1.63184988e-04, 1.68920757e-04, 1.89777682e-04,\n",
      "       1.84737946e-04, 1.59298885e-04, 1.71465654e-04, 1.46840786e-04,\n",
      "       1.41427430e-04, 1.63994933e-04, 1.61026634e-04, 1.92928972e-04,\n",
      "       1.72019500e-04, 1.79211915e-04, 1.58827141e-04, 1.00142010e-04,\n",
      "       1.64402401e-04, 2.00876399e-04, 2.21351947e-04, 1.65101708e-04,\n",
      "       1.96162538e-04, 1.24753293e-04, 1.99163420e-04, 1.92213192e-04,\n",
      "       1.43995028e-04, 1.80277071e-04, 1.11551824e-04, 1.99444956e-04,\n",
      "       2.27678029e-04, 9.54621501e-05, 1.55143687e-04, 1.68130442e-04,\n",
      "       1.68059632e-04, 1.84194156e-04, 1.55305155e-04, 1.90490347e-04,\n",
      "       2.01812538e-04, 1.29485314e-04, 2.05802498e-04, 1.83620956e-04,\n",
      "       2.33307044e-04, 1.80574658e-04, 1.92320105e-04, 1.93968212e-04,\n",
      "       1.35852562e-04, 1.60104464e-04, 1.65452599e-04, 2.00352297e-04,\n",
      "       1.36435221e-04, 1.65017205e-04, 1.78614166e-04, 2.13853855e-04,\n",
      "       1.98299051e-04, 2.11837134e-04, 1.64983561e-04, 1.52220164e-04,\n",
      "       1.91675223e-04, 1.65696620e-04, 1.60375115e-04, 2.36173189e-04,\n",
      "       1.54716501e-04, 2.24043324e-04, 1.93039843e-04, 1.57229195e-04,\n",
      "       1.76524831e-04, 2.22940289e-04, 1.69446939e-04, 1.72225948e-04,\n",
      "       1.85401790e-04, 1.63318327e-04, 2.06993980e-04, 1.55073154e-04,\n",
      "       1.86640129e-04, 1.09354878e-04, 2.17699548e-04, 1.58841998e-04,\n",
      "       1.77778478e-04, 2.43236631e-04, 2.20990187e-04, 1.05461091e-04,\n",
      "       1.73258843e-04, 1.68361526e-04, 1.82205782e-04, 1.81516953e-04,\n",
      "       2.54225481e-04, 2.05312768e-04, 1.71365187e-04, 1.72560933e-04,\n",
      "       1.90668536e-04, 2.48444179e-04, 1.78098388e-04, 2.23683106e-04,\n",
      "       1.29057837e-04, 1.39222102e-04, 1.61064119e-04, 1.12772716e-04,\n",
      "       1.48735809e-04, 1.91718806e-04, 2.16632267e-04, 2.00317605e-04,\n",
      "       2.16445056e-04, 2.07512683e-04, 2.15243184e-04, 2.58694374e-04,\n",
      "       1.89384242e-04, 2.09494930e-04, 1.20783217e-04, 1.69196544e-04,\n",
      "       1.99046830e-04, 1.88699647e-04, 1.71385051e-04, 1.78336326e-04,\n",
      "       1.21533703e-04, 2.05603239e-04, 1.62350640e-04, 1.65909179e-04,\n",
      "       2.03998890e-04, 1.98730326e-04, 1.68323488e-04, 1.91233354e-04,\n",
      "       1.72683751e-04, 1.73232969e-04, 2.40684996e-04, 2.10076425e-04,\n",
      "       1.08301574e-04, 1.78504080e-04, 1.69930208e-04, 1.91259416e-04,\n",
      "       1.24213140e-04, 2.38124630e-04, 1.57978822e-04, 1.54378155e-04,\n",
      "       2.07204022e-04, 2.16075423e-04, 1.90525883e-04, 1.78042013e-04,\n",
      "       2.10018741e-04, 2.21366005e-04, 2.41417991e-04, 1.91712970e-04,\n",
      "       2.01329865e-04, 1.90327773e-04, 2.30746620e-04, 2.00607974e-04,\n",
      "       1.85893019e-04, 2.04774391e-04, 2.10305632e-04, 1.69140505e-04,\n",
      "       1.56752445e-04, 1.55449263e-04, 1.74281668e-04, 1.64900048e-04,\n",
      "       1.70537140e-04, 1.08384884e-04, 1.80546805e-04, 2.02280964e-04,\n",
      "       1.67511345e-04, 1.77759342e-04, 1.80263654e-04, 1.12777430e-04,\n",
      "       1.57966744e-04, 1.60611729e-04, 1.67523394e-04, 2.14165761e-04,\n",
      "       1.96031382e-04, 2.10723738e-04, 1.83273572e-04, 1.70626779e-04,\n",
      "       1.54048408e-04, 1.89932340e-04, 1.35697817e-04, 1.42846155e-04,\n",
      "       1.95364337e-04, 1.60773270e-04, 1.98594818e-04, 1.71617794e-04,\n",
      "       2.03104632e-04, 1.60235068e-04, 1.93405242e-04, 2.10996601e-04,\n",
      "       1.64817204e-04, 1.52632754e-04, 1.99540533e-04, 6.83821781e-05,\n",
      "       1.84095814e-04, 1.68650804e-04, 1.96906971e-04, 1.77345835e-04,\n",
      "       2.18450397e-04, 1.92666266e-04, 1.70739091e-04, 2.42481270e-04,\n",
      "       1.78350791e-04, 1.55385249e-04, 2.72243837e-04, 1.60574811e-04,\n",
      "       1.57572795e-04, 1.65692909e-04, 1.69740611e-04, 1.69038161e-04,\n",
      "       1.88244070e-04, 2.02741619e-04, 2.65453767e-04, 1.72277520e-04,\n",
      "       1.88985447e-04, 1.84861143e-04, 2.16185508e-04, 1.63458171e-04,\n",
      "       2.00402370e-04, 2.11711813e-04, 1.93971748e-04, 1.76151952e-04,\n",
      "       1.91171959e-04, 1.95691842e-04, 1.90979408e-04, 1.61724049e-04,\n",
      "       1.53708796e-04, 1.93035055e-04, 2.21566661e-04, 1.47709623e-04,\n",
      "       1.62061697e-04, 2.17315799e-04, 1.79584284e-04, 2.00759547e-04,\n",
      "       1.56242488e-04, 1.61831966e-04, 7.51843108e-05, 7.55232613e-05,\n",
      "       2.22828457e-04, 2.46387004e-04, 1.62520300e-04, 1.79447496e-04,\n",
      "       1.43202080e-04, 1.52427659e-04, 1.71381995e-04, 2.16693908e-04,\n",
      "       2.18581670e-04, 1.82918593e-04, 1.61352888e-04, 1.66545680e-04,\n",
      "       1.85951387e-04, 2.01503222e-04, 1.64196477e-04, 2.44440133e-04,\n",
      "       1.66386351e-04, 1.81688010e-04, 2.12328290e-04, 2.13883526e-04,\n",
      "       1.88003774e-04, 2.73000769e-04, 1.78795846e-04, 1.69962965e-04,\n",
      "       1.57203278e-04, 2.36226086e-04, 1.79713927e-04, 2.25573633e-04,\n",
      "       1.79763170e-04, 1.84974604e-04, 1.94637963e-04, 2.28184828e-04,\n",
      "       1.76807051e-04, 2.12831903e-04, 1.75581794e-04, 1.26204774e-04,\n",
      "       2.01106770e-04, 1.46727150e-04, 1.55911068e-04, 2.07381279e-04,\n",
      "       1.51796485e-04, 2.25630254e-04, 1.71717678e-04, 2.09206555e-04,\n",
      "       1.77459733e-04, 2.08901358e-04, 2.25218741e-04, 1.65863996e-04,\n",
      "       1.75547975e-04, 1.54883586e-04, 1.75194524e-04, 1.74277389e-04,\n",
      "       1.56533410e-04, 1.70916232e-04, 1.22734273e-04, 1.40608390e-04,\n",
      "       1.92293679e-04, 1.59328018e-04, 1.32310248e-04, 2.05653341e-04,\n",
      "       1.57913222e-04, 1.40183882e-04, 1.11643662e-04, 1.67279213e-04,\n",
      "       1.87862301e-04, 1.77653463e-04, 1.44037636e-04, 1.75541427e-04,\n",
      "       1.02035796e-04, 1.57678296e-04, 1.74644389e-04, 1.72414584e-04],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'model_1/conv2d_5/Conv2D', 'index': 5, 'shape': array([512,   1,   1, 256], dtype=int32), 'shape_signature': array([512,   1,   1, 256], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00120616, 0.00138913, 0.0028495 , 0.0024513 , 0.0021087 ,\n",
      "       0.00306423, 0.00346124, 0.00124299, 0.00285021, 0.00266553,\n",
      "       0.00238911, 0.0024585 , 0.00261134, 0.00332459, 0.00265446,\n",
      "       0.00214866, 0.0030013 , 0.00293459, 0.00318573, 0.00337399,\n",
      "       0.00229546, 0.00267317, 0.00246435, 0.00268613, 0.00253456,\n",
      "       0.00239995, 0.00324892, 0.00311402, 0.0021837 , 0.00261598,\n",
      "       0.00251956, 0.00317801, 0.00161762, 0.00304282, 0.0022963 ,\n",
      "       0.00226442, 0.00262083, 0.00263314, 0.0029233 , 0.00295481,\n",
      "       0.00252754, 0.00321345, 0.00401772, 0.00219518, 0.00223967,\n",
      "       0.00399836, 0.00132269, 0.00231271, 0.00367865, 0.00259964,\n",
      "       0.00246062, 0.00250173, 0.00109739, 0.00241236, 0.00261766,\n",
      "       0.00206118, 0.00362778, 0.00396246, 0.00240346, 0.00257171,\n",
      "       0.00297727, 0.0027104 , 0.00314712, 0.00241079, 0.00227171,\n",
      "       0.00274034, 0.00318682, 0.00208392, 0.0031232 , 0.00294492,\n",
      "       0.00290027, 0.0024846 , 0.00290705, 0.00236224, 0.00243345,\n",
      "       0.00219921, 0.00296814, 0.00328522, 0.00265402, 0.00248422,\n",
      "       0.00254007, 0.00259228, 0.00232088, 0.00325766, 0.0027694 ,\n",
      "       0.00446663, 0.00191206, 0.00309142, 0.00262792, 0.00286058,\n",
      "       0.00355353, 0.00251315, 0.00361865, 0.0014156 , 0.00253187,\n",
      "       0.00229854, 0.00308014, 0.00291464, 0.00269888, 0.00439992,\n",
      "       0.00240999, 0.00306462, 0.00265566, 0.00154911, 0.00266185,\n",
      "       0.00270683, 0.00372561, 0.00305439, 0.00274481, 0.00245999,\n",
      "       0.0025134 , 0.00215595, 0.00225967, 0.00270606, 0.00233023,\n",
      "       0.0031245 , 0.00290103, 0.00243356, 0.00310153, 0.00259263,\n",
      "       0.00273548, 0.00113465, 0.0028241 , 0.00233767, 0.00296323,\n",
      "       0.00217098, 0.00272191, 0.00285708, 0.00168952, 0.00252455,\n",
      "       0.00322942, 0.00264968, 0.00338279, 0.00120665, 0.00245236,\n",
      "       0.00251757, 0.00264815, 0.00257772, 0.0020579 , 0.00314022,\n",
      "       0.00271056, 0.00220155, 0.00263022, 0.00231245, 0.00189715,\n",
      "       0.00176084, 0.00216046, 0.00236732, 0.00306523, 0.00275407,\n",
      "       0.00265013, 0.00309515, 0.00284368, 0.00253222, 0.00205713,\n",
      "       0.00273991, 0.00256074, 0.00201628, 0.00267024, 0.00349725,\n",
      "       0.00206105, 0.00233931, 0.00301419, 0.00276241, 0.00271168,\n",
      "       0.00239661, 0.00242279, 0.00206896, 0.00322196, 0.00218941,\n",
      "       0.00258084, 0.00247621, 0.00318134, 0.00269139, 0.00297217,\n",
      "       0.00263036, 0.00271941, 0.00245619, 0.00244459, 0.00298148,\n",
      "       0.00330165, 0.00235895, 0.00267526, 0.00255497, 0.00219311,\n",
      "       0.0024737 , 0.00306261, 0.00250935, 0.00338936, 0.00233655,\n",
      "       0.00282366, 0.00251764, 0.00265922, 0.00236799, 0.00308315,\n",
      "       0.00254533, 0.00232105, 0.00232627, 0.00219104, 0.00251609,\n",
      "       0.0025113 , 0.00333565, 0.00252655, 0.0029448 , 0.00212377,\n",
      "       0.00300854, 0.00239304, 0.00326645, 0.00262687, 0.00306845,\n",
      "       0.00289213, 0.00241547, 0.00231231, 0.00243654, 0.00252218,\n",
      "       0.0028336 , 0.00275835, 0.00237851, 0.00256018, 0.0021925 ,\n",
      "       0.00211167, 0.00244863, 0.00240431, 0.00288065, 0.00256845,\n",
      "       0.00267584, 0.00237147, 0.00149523, 0.00245471, 0.00299931,\n",
      "       0.00330504, 0.00246516, 0.00292893, 0.00186271, 0.00297374,\n",
      "       0.00286996, 0.00215001, 0.00269174, 0.0016656 , 0.00297794,\n",
      "       0.00339949, 0.00142536, 0.00231647, 0.00251038, 0.00250932,\n",
      "       0.00275023, 0.00231888, 0.00284424, 0.00301329, 0.00193336,\n",
      "       0.00307286, 0.00274167, 0.00348354, 0.00269618, 0.00287156,\n",
      "       0.00289617, 0.00202843, 0.00239054, 0.00247039, 0.00299149,\n",
      "       0.00203713, 0.00246389, 0.00266691, 0.00319308, 0.00296083,\n",
      "       0.00316297, 0.00246339, 0.00227282, 0.00286193, 0.00247404,\n",
      "       0.00239458, 0.00352633, 0.00231009, 0.00334522, 0.0028823 ,\n",
      "       0.00234761, 0.00263572, 0.00332875, 0.00253003, 0.00257153,\n",
      "       0.00276826, 0.00243853, 0.00309065, 0.00231542, 0.00278675,\n",
      "       0.00163279, 0.0032505 , 0.00237169, 0.00265443, 0.0036318 ,\n",
      "       0.00329963, 0.00157465, 0.00258695, 0.00251383, 0.00272054,\n",
      "       0.00271025, 0.00379587, 0.00306555, 0.00255868, 0.00257653,\n",
      "       0.0028469 , 0.00370955, 0.00265921, 0.00333984, 0.00192698,\n",
      "       0.00207874, 0.00240487, 0.00168382, 0.00222079, 0.00286258,\n",
      "       0.00323457, 0.00299097, 0.00323177, 0.0030984 , 0.00321382,\n",
      "       0.0038626 , 0.00282772, 0.003128  , 0.00180343, 0.0025263 ,\n",
      "       0.00297199, 0.0028175 , 0.00255897, 0.00266276, 0.00181464,\n",
      "       0.00306989, 0.00242408, 0.00247721, 0.00304593, 0.00296727,\n",
      "       0.00251326, 0.00285533, 0.00257836, 0.00258656, 0.0035937 ,\n",
      "       0.00313668, 0.00161707, 0.00266527, 0.00253725, 0.00285572,\n",
      "       0.00185464, 0.00355547, 0.0023588 , 0.00230504, 0.00309379,\n",
      "       0.00322625, 0.00284477, 0.00265837, 0.00313582, 0.00330525,\n",
      "       0.00360464, 0.00286249, 0.00300608, 0.00284181, 0.00344531,\n",
      "       0.0029953 , 0.00277559, 0.00305751, 0.0031401 , 0.00252546,\n",
      "       0.00234049, 0.00232103, 0.00260222, 0.00246214, 0.00254631,\n",
      "       0.00161831, 0.00269577, 0.00302028, 0.00250113, 0.00265415,\n",
      "       0.00269154, 0.00168389, 0.00235862, 0.00239812, 0.00250131,\n",
      "       0.00319774, 0.00292697, 0.00314634, 0.00273648, 0.00254765,\n",
      "       0.00230012, 0.0028359 , 0.00202612, 0.00213285, 0.00291701,\n",
      "       0.00240053, 0.00296525, 0.00256245, 0.00303258, 0.00239249,\n",
      "       0.00288776, 0.00315042, 0.00246091, 0.00227898, 0.00297937,\n",
      "       0.00102102, 0.00274876, 0.00251815, 0.00294004, 0.00264797,\n",
      "       0.00326171, 0.00287673, 0.00254933, 0.00362052, 0.00266298,\n",
      "       0.00232008, 0.00406491, 0.00239756, 0.00235274, 0.00247398,\n",
      "       0.00253442, 0.00252393, 0.0028107 , 0.00302716, 0.00396353,\n",
      "       0.0025723 , 0.00282177, 0.00276019, 0.00322789, 0.00244062,\n",
      "       0.00299223, 0.0031611 , 0.00289622, 0.00263015, 0.00285441,\n",
      "       0.0029219 , 0.00285154, 0.00241472, 0.00229505, 0.00288223,\n",
      "       0.00330824, 0.00220547, 0.00241976, 0.00324477, 0.0026814 ,\n",
      "       0.00299757, 0.00233288, 0.00241633, 0.00112259, 0.00112765,\n",
      "       0.00332708, 0.00367884, 0.00242661, 0.00267935, 0.00213817,\n",
      "       0.00227592, 0.00255893, 0.00323549, 0.00326367, 0.00273118,\n",
      "       0.00240918, 0.00248672, 0.00277646, 0.00300867, 0.00245164,\n",
      "       0.00364977, 0.00248434, 0.00271281, 0.0031703 , 0.00319352,\n",
      "       0.00280711, 0.00407621, 0.00266962, 0.00253774, 0.00234722,\n",
      "       0.00352712, 0.00268333, 0.00336807, 0.00268407, 0.00276188,\n",
      "       0.00290617, 0.00340706, 0.00263993, 0.00317782, 0.00262164,\n",
      "       0.00188438, 0.00300275, 0.0021908 , 0.00232793, 0.00309644,\n",
      "       0.00226649, 0.00336892, 0.00256394, 0.00312369, 0.00264967,\n",
      "       0.00311913, 0.00336277, 0.00247654, 0.00262113, 0.00231259,\n",
      "       0.00261585, 0.00260216, 0.00233722, 0.00255197, 0.00183256,\n",
      "       0.00209944, 0.00287116, 0.00237895, 0.00197554, 0.00307064,\n",
      "       0.00235782, 0.0020931 , 0.00166697, 0.00249767, 0.002805  ,\n",
      "       0.00265257, 0.00215065, 0.00262103, 0.00152351, 0.00235432,\n",
      "       0.00260764, 0.00257435], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'model_1/re_lu_9/Relu;model_1/batch_normalization_9/FusedBatchNormV3;model_1/depthwise_conv2d_4/depthwise;model_1/depthwise_conv2d_4/BiasAdd/ReadVariableOp;model_1/depthwise_conv2d_4/BiasAdd', 'index': 6, 'shape': array([256], dtype=int32), 'shape_signature': array([256], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([2.35227344e-04, 3.26765701e-04, 2.14975968e-04, 4.02898091e-04,\n",
      "       2.65916053e-04, 4.29281674e-04, 1.44106583e-04, 2.47087795e-04,\n",
      "       4.42851160e-04, 4.34774614e-04, 2.29265686e-04, 2.61042413e-04,\n",
      "       3.15512036e-04, 2.74713151e-04, 4.31099674e-04, 3.86822212e-04,\n",
      "       2.57052539e-04, 3.98499309e-04, 3.43776454e-04, 5.47198171e-04,\n",
      "       2.88842886e-04, 2.62354704e-04, 2.65283423e-04, 3.28695693e-04,\n",
      "       8.08040902e-04, 4.56050358e-04, 3.01734981e-04, 2.91074655e-04,\n",
      "       1.74201661e-04, 2.20065005e-04, 6.62965700e-04, 3.69276444e-04,\n",
      "       2.92789104e-04, 3.83810897e-04, 2.24998978e-04, 3.45185341e-04,\n",
      "       6.35321252e-04, 4.54051158e-04, 2.28763325e-04, 4.01601341e-04,\n",
      "       5.57837600e-04, 3.02460598e-04, 2.48098571e-04, 2.30450605e-04,\n",
      "       3.24960158e-04, 4.31511289e-04, 2.34755673e-04, 3.16214137e-04,\n",
      "       2.61897600e-04, 3.13145283e-04, 1.62087817e-04, 4.33934212e-04,\n",
      "       2.88856216e-04, 3.28445429e-04, 2.64041853e-04, 4.98688256e-04,\n",
      "       3.66411055e-04, 2.77835818e-04, 6.89280278e-05, 3.25865112e-04,\n",
      "       2.55940831e-04, 4.70440951e-04, 3.90823669e-04, 4.90429753e-04,\n",
      "       5.14728425e-04, 2.19290843e-04, 3.23040964e-04, 3.47724912e-04,\n",
      "       3.46547284e-04, 4.49220621e-04, 3.14858800e-04, 4.19821241e-04,\n",
      "       6.87264081e-04, 2.84380134e-04, 2.95479374e-04, 2.44966941e-04,\n",
      "       3.24683497e-04, 3.35105578e-04, 2.86488124e-04, 4.76475223e-04,\n",
      "       2.67279829e-04, 4.21460776e-04, 2.56573723e-04, 4.14098817e-04,\n",
      "       3.20336054e-04, 2.51045276e-04, 2.27285462e-04, 2.79192347e-04,\n",
      "       9.74506373e-04, 3.97107215e-04, 7.74908694e-04, 1.12159825e-04,\n",
      "       3.63323954e-04, 3.30574374e-04, 2.69534939e-04, 3.72193957e-04,\n",
      "       2.50746147e-04, 2.03686825e-04, 2.12625193e-04, 4.30034968e-04,\n",
      "       3.90587724e-04, 4.04589373e-04, 3.53913376e-04, 3.86284431e-04,\n",
      "       3.13439145e-04, 3.82385420e-04, 3.85972642e-04, 3.77977907e-04,\n",
      "       4.63776611e-04, 2.11418883e-04, 4.28029074e-04, 3.82256287e-04,\n",
      "       2.33629238e-04, 3.31880728e-04, 4.70855128e-04, 3.35564720e-04,\n",
      "       3.36481491e-04, 2.57622538e-04, 6.25507673e-05, 2.71354686e-04,\n",
      "       5.05054137e-04, 3.76886572e-04, 3.78779281e-04, 3.95528477e-04,\n",
      "       7.66008161e-04, 3.97462252e-04, 3.60270584e-04, 2.65102397e-04,\n",
      "       3.14453879e-04, 3.83060717e-04, 2.62176734e-04, 2.81316054e-04,\n",
      "       2.77068873e-04, 2.72457255e-04, 2.26466305e-04, 3.02778819e-04,\n",
      "       3.58561927e-04, 2.09576829e-04, 2.94480851e-04, 3.13828146e-04,\n",
      "       3.57716111e-04, 2.68533971e-04, 2.70863035e-04, 4.29375155e-04,\n",
      "       1.03991479e-03, 3.30009672e-04, 3.08902934e-04, 3.38351063e-04,\n",
      "       4.56689188e-04, 4.05302038e-04, 2.98324885e-04, 2.60706875e-04,\n",
      "       2.50064710e-04, 2.56219966e-04, 3.60703591e-04, 3.90575209e-04,\n",
      "       2.14042229e-04, 1.70375075e-04, 4.90509381e-04, 4.27162304e-04,\n",
      "       4.32243396e-04, 2.98608997e-04, 3.25806468e-04, 4.81381896e-04,\n",
      "       3.01079039e-04, 3.32103751e-04, 2.55736668e-04, 2.70486315e-04,\n",
      "       2.90728378e-04, 2.54761369e-04, 3.17282655e-04, 8.23538212e-05,\n",
      "       9.30249371e-05, 8.01978458e-04, 4.53233632e-04, 4.77407710e-04,\n",
      "       4.65254387e-04, 3.52845731e-04, 3.94928560e-04, 2.73067475e-04,\n",
      "       5.30250196e-04, 1.76159287e-04, 4.58023947e-04, 4.78907692e-04,\n",
      "       2.94979691e-04, 2.90382624e-04, 6.22356660e-04, 6.49508729e-04,\n",
      "       2.19604757e-04, 5.31136175e-04, 2.34553547e-04, 2.48818978e-04,\n",
      "       3.20065825e-04, 2.71710480e-04, 2.38835113e-04, 2.95034290e-04,\n",
      "       1.38543823e-04, 4.77119436e-04, 2.60240922e-04, 4.05370054e-04,\n",
      "       3.07557144e-04, 2.46519892e-04, 4.03843966e-04, 3.09936528e-04,\n",
      "       2.98837229e-04, 4.01377009e-04, 3.71914211e-04, 2.80087377e-04,\n",
      "       3.14272969e-04, 2.35132029e-04, 4.12047579e-04, 2.59494554e-04,\n",
      "       2.28108489e-04, 3.77136806e-04, 2.88099458e-04, 3.68179288e-04,\n",
      "       3.61846352e-04, 1.03092671e-03, 2.87523639e-04, 5.16985892e-04,\n",
      "       3.17322410e-04, 5.41218789e-04, 3.44213331e-04, 3.33384349e-04,\n",
      "       2.96139595e-04, 2.39079047e-04, 3.91841721e-04, 4.89767874e-04,\n",
      "       3.36964440e-04, 4.24216531e-04, 2.35685860e-04, 4.74968692e-04,\n",
      "       3.86550964e-04, 3.26937647e-04, 3.56820150e-04, 2.04627373e-04,\n",
      "       3.25657369e-04, 4.81611205e-04, 2.96429469e-04, 3.64874781e-04,\n",
      "       2.77686660e-04, 2.32530248e-04, 3.36787401e-04, 4.42245830e-04,\n",
      "       5.30569640e-04, 3.61179700e-04, 3.13467230e-04, 1.57271803e-04,\n",
      "       2.56187312e-04, 2.61738605e-04, 3.23012238e-04, 3.91235022e-04,\n",
      "       2.81046639e-04, 4.03675687e-04, 2.26165095e-04, 3.73172836e-04],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'model_1/batch_normalization_9/FusedBatchNormV3;model_1/depthwise_conv2d_4/depthwise;model_1/depthwise_conv2d_4/BiasAdd/ReadVariableOp;model_1/depthwise_conv2d_4/BiasAdd', 'index': 7, 'shape': array([  1,   3,   3, 256], dtype=int32), 'shape_signature': array([  1,   3,   3, 256], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00486081, 0.00675238, 0.00444233, 0.00832561, 0.00549497,\n",
      "       0.0088708 , 0.00297786, 0.0051059 , 0.00915121, 0.00898431,\n",
      "       0.00473761, 0.00539426, 0.00651983, 0.00567675, 0.00890837,\n",
      "       0.00799341, 0.00531181, 0.00823471, 0.0071039 , 0.01130747,\n",
      "       0.00596874, 0.00542138, 0.0054819 , 0.00679227, 0.0166976 ,\n",
      "       0.00942396, 0.00623514, 0.00601485, 0.00359976, 0.00454749,\n",
      "       0.01369972, 0.00763084, 0.00605028, 0.00793118, 0.00464945,\n",
      "       0.00713301, 0.01312847, 0.00938265, 0.00472723, 0.00829881,\n",
      "       0.01152732, 0.00625014, 0.00512678, 0.0047621 , 0.00671507,\n",
      "       0.00891688, 0.00485106, 0.00653434, 0.00541193, 0.00647093,\n",
      "       0.00334943, 0.00896695, 0.00596901, 0.00678709, 0.00545624,\n",
      "       0.01030504, 0.00757163, 0.00574128, 0.00142435, 0.00673377,\n",
      "       0.00528884, 0.00972133, 0.0080761 , 0.01013439, 0.0106365 ,\n",
      "       0.00453149, 0.00667541, 0.00718549, 0.00716116, 0.00928283,\n",
      "       0.00650634, 0.00867531, 0.01420183, 0.00587652, 0.00610587,\n",
      "       0.00506207, 0.00670936, 0.00692472, 0.00592008, 0.00984603,\n",
      "       0.00552315, 0.00870919, 0.00530192, 0.00855706, 0.00661952,\n",
      "       0.00518767, 0.00469669, 0.00576931, 0.02013749, 0.00820594,\n",
      "       0.01601294, 0.0023177 , 0.00750783, 0.00683109, 0.00556975,\n",
      "       0.00769113, 0.00518149, 0.00420905, 0.00439375, 0.00888637,\n",
      "       0.00807122, 0.00836056, 0.00731337, 0.0079823 , 0.006477  ,\n",
      "       0.00790173, 0.00797585, 0.00781065, 0.00958362, 0.00436882,\n",
      "       0.00884492, 0.00789906, 0.00482778, 0.00685808, 0.00972989,\n",
      "       0.00693421, 0.00695315, 0.00532359, 0.00129257, 0.00560735,\n",
      "       0.01043659, 0.0077881 , 0.00782721, 0.00817332, 0.01582902,\n",
      "       0.00821328, 0.00744474, 0.00547816, 0.00649797, 0.00791568,\n",
      "       0.0054177 , 0.0058132 , 0.00572543, 0.00563014, 0.00467977,\n",
      "       0.00625671, 0.00740943, 0.00433076, 0.00608524, 0.00648504,\n",
      "       0.00739195, 0.00554907, 0.00559719, 0.00887274, 0.02148911,\n",
      "       0.00681942, 0.00638326, 0.00699179, 0.00943716, 0.00837528,\n",
      "       0.00616467, 0.00538732, 0.00516741, 0.00529461, 0.00745369,\n",
      "       0.00807096, 0.00442303, 0.00352068, 0.01013603, 0.00882701,\n",
      "       0.00893201, 0.00617055, 0.00673256, 0.00994742, 0.00622159,\n",
      "       0.00686269, 0.00528462, 0.00558941, 0.0060077 , 0.00526446,\n",
      "       0.00655642, 0.00170178, 0.0019223 , 0.01657232, 0.00936576,\n",
      "       0.0098653 , 0.00961416, 0.00729131, 0.00816092, 0.00564275,\n",
      "       0.01095725, 0.00364021, 0.00946474, 0.00989629, 0.00609555,\n",
      "       0.00600055, 0.01286056, 0.01342164, 0.00453798, 0.01097556,\n",
      "       0.00484688, 0.00514167, 0.00661394, 0.00561471, 0.00493536,\n",
      "       0.00609668, 0.00286291, 0.00985934, 0.0053777 , 0.00837669,\n",
      "       0.00635545, 0.00509416, 0.00834515, 0.00640462, 0.00617526,\n",
      "       0.00829417, 0.00768535, 0.00578781, 0.00649423, 0.00485884,\n",
      "       0.00851467, 0.00536227, 0.0047137 , 0.00779327, 0.00595337,\n",
      "       0.00760817, 0.0074773 , 0.02130338, 0.00594147, 0.01068315,\n",
      "       0.00655725, 0.01118391, 0.00711293, 0.00688915, 0.00611952,\n",
      "       0.0049404 , 0.00809713, 0.01012071, 0.00696313, 0.00876614,\n",
      "       0.00487028, 0.00981489, 0.0079878 , 0.00675594, 0.00737344,\n",
      "       0.00422848, 0.00672948, 0.00995216, 0.00612551, 0.00753988,\n",
      "       0.0057382 , 0.00480507, 0.00695948, 0.0091387 , 0.01096385,\n",
      "       0.00746353, 0.00647758, 0.00324991, 0.00529393, 0.00540864,\n",
      "       0.00667482, 0.0080846 , 0.00580763, 0.00834167, 0.00467354,\n",
      "       0.00771136], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 3}, 'sparsity_parameters': {}}, {'name': 'model_1/re_lu_8/Relu;model_1/batch_normalization_8/FusedBatchNormV3;model_1/conv2d_4/BiasAdd/ReadVariableOp;model_1/conv2d_4/BiasAdd;model_1/depthwise_conv2d_4/depthwise;model_1/conv2d_4/Conv2D', 'index': 8, 'shape': array([256], dtype=int32), 'shape_signature': array([256], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([1.96722991e-04, 1.78981092e-04, 2.37816843e-04, 1.37169030e-04,\n",
      "       2.29189551e-04, 1.74819928e-04, 7.31013788e-05, 2.40683788e-04,\n",
      "       1.33045018e-04, 8.96914789e-05, 2.38043518e-04, 2.35538682e-04,\n",
      "       1.49622079e-04, 1.91572690e-04, 1.60861717e-04, 1.45194703e-04,\n",
      "       2.55992520e-04, 1.51528278e-04, 1.63339442e-04, 1.39973083e-04,\n",
      "       1.38242714e-04, 2.18286208e-04, 1.39198470e-04, 2.11563747e-04,\n",
      "       9.96516610e-05, 1.05289320e-04, 1.41642726e-04, 2.88414070e-04,\n",
      "       1.14371171e-04, 2.00532246e-04, 1.09660832e-04, 1.46652601e-04,\n",
      "       1.60052412e-04, 2.25000098e-04, 2.20057176e-04, 2.09270671e-04,\n",
      "       1.07663029e-04, 1.71112173e-04, 2.10349943e-04, 1.63692544e-04,\n",
      "       1.25725011e-04, 1.86701771e-04, 1.91491010e-04, 2.51580990e-04,\n",
      "       1.47089871e-04, 1.64861340e-04, 9.18443620e-05, 2.52060941e-04,\n",
      "       2.17082299e-04, 2.02915428e-04, 1.04260100e-04, 1.43791549e-04,\n",
      "       1.54029287e-04, 1.67812628e-04, 1.64428566e-04, 1.07561347e-04,\n",
      "       1.29176289e-04, 2.09523656e-04, 1.06603489e-04, 1.77639013e-04,\n",
      "       2.08275073e-04, 1.37597541e-04, 1.90362392e-04, 1.13652823e-04,\n",
      "       1.57731134e-04, 1.67969018e-04, 1.36937422e-04, 1.87100624e-04,\n",
      "       1.36112794e-04, 1.31413006e-04, 2.47222662e-04, 1.29834676e-04,\n",
      "       1.15723262e-04, 2.03382995e-04, 1.44944788e-04, 1.63849472e-04,\n",
      "       9.36175711e-05, 1.23360005e-04, 2.05962482e-04, 1.19669348e-04,\n",
      "       1.89027414e-04, 1.15128409e-04, 2.18683315e-04, 1.29906606e-04,\n",
      "       2.16427521e-04, 1.62769342e-04, 9.71533009e-05, 1.35024471e-04,\n",
      "       1.12443391e-04, 2.11171558e-04, 1.16159652e-04, 1.22345926e-04,\n",
      "       1.97997186e-04, 1.83732365e-04, 2.10274447e-04, 1.71596941e-04,\n",
      "       2.16577711e-04, 2.05660443e-04, 2.38870780e-04, 1.18879740e-04,\n",
      "       1.57685296e-04, 1.04778010e-04, 6.54600153e-05, 1.44444391e-04,\n",
      "       1.54864392e-04, 1.57119299e-04, 1.49846164e-04, 1.78505274e-04,\n",
      "       1.45011873e-04, 1.28410029e-04, 1.16518560e-04, 1.20493583e-04,\n",
      "       1.98561713e-04, 1.12852184e-04, 1.71945707e-04, 1.53929592e-04,\n",
      "       1.83217577e-04, 2.12821251e-04, 1.24246973e-04, 2.31569444e-04,\n",
      "       1.20690835e-04, 9.11865645e-05, 1.45224956e-04, 1.69771709e-04,\n",
      "       1.04439503e-04, 2.12530795e-04, 1.83064345e-04, 2.63196154e-04,\n",
      "       2.22481453e-04, 1.68630155e-04, 1.65323843e-04, 2.51062127e-04,\n",
      "       1.82129748e-04, 2.26687232e-04, 2.03335934e-04, 2.20911199e-04,\n",
      "       1.95733504e-04, 2.28405770e-04, 1.72973174e-04, 1.16343006e-04,\n",
      "       1.87338956e-04, 1.41363955e-04, 1.61474076e-04, 1.85394660e-04,\n",
      "       9.67658634e-05, 2.13672887e-04, 1.67061022e-04, 1.94915454e-04,\n",
      "       1.57731789e-04, 1.16271534e-04, 2.06087061e-04, 1.68887316e-04,\n",
      "       2.02250725e-04, 2.04064694e-04, 1.20658944e-04, 1.05917912e-04,\n",
      "       2.26325792e-04, 1.00931837e-04, 1.75048059e-04, 1.39515803e-04,\n",
      "       8.71794764e-05, 1.79527313e-04, 1.25155391e-04, 1.54429305e-04,\n",
      "       1.19257340e-04, 1.67359394e-04, 2.18351939e-04, 1.95785047e-04,\n",
      "       2.05826989e-04, 2.34402512e-04, 1.84407909e-04, 1.26733838e-04,\n",
      "       1.25524239e-04, 1.07364889e-04, 1.57053320e-04, 1.93735206e-04,\n",
      "       1.29562424e-04, 1.02108010e-04, 1.67401915e-04, 2.16705273e-04,\n",
      "       1.22523561e-04, 1.08564695e-04, 1.09398119e-04, 1.45398109e-04,\n",
      "       2.27407043e-04, 1.31370063e-04, 7.15401766e-05, 1.08604887e-04,\n",
      "       2.57931330e-04, 1.23978927e-04, 9.46119253e-05, 1.93724569e-04,\n",
      "       2.32426188e-04, 1.85906567e-04, 1.33804278e-04, 1.67116668e-04,\n",
      "       1.11797162e-04, 1.54600391e-04, 1.53798101e-04, 1.00949248e-04,\n",
      "       1.28999571e-04, 2.19054506e-04, 1.72292173e-04, 2.19046779e-04,\n",
      "       1.95480941e-04, 1.31971959e-04, 1.06938169e-04, 1.14705421e-04,\n",
      "       1.87514946e-04, 2.24571282e-04, 1.71315711e-04, 2.25659431e-04,\n",
      "       2.25225129e-04, 1.18725817e-04, 1.63415301e-04, 1.04964492e-04,\n",
      "       1.27913692e-04, 1.20226665e-04, 1.70590734e-04, 1.30668472e-04,\n",
      "       2.10930535e-04, 1.27159976e-04, 1.12850357e-04, 2.41171438e-04,\n",
      "       1.70337589e-04, 2.18935922e-04, 1.17254422e-04, 1.06156098e-04,\n",
      "       1.53374465e-04, 1.17342301e-04, 2.02450508e-04, 1.81993353e-04,\n",
      "       1.27635081e-04, 1.71596505e-04, 2.34461855e-04, 2.01958406e-04,\n",
      "       2.06410681e-04, 8.95900157e-05, 1.60033800e-04, 1.51752130e-04,\n",
      "       2.66612973e-04, 2.09423888e-04, 2.20082627e-04, 1.37791969e-04,\n",
      "       1.68819592e-04, 1.21892263e-04, 1.79909490e-04, 9.70744077e-05,\n",
      "       1.02271348e-04, 2.07880832e-04, 2.14475251e-04, 9.01321910e-05,\n",
      "       1.92250591e-04, 1.20594246e-04, 1.09799956e-04, 1.17996642e-04],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'model_1/conv2d_4/Conv2D', 'index': 9, 'shape': array([256,   1,   1, 256], dtype=int32), 'shape_signature': array([256,   1,   1, 256], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00212942, 0.00193737, 0.00257423, 0.00148478, 0.00248085,\n",
      "       0.00189233, 0.00079128, 0.00260527, 0.00144014, 0.00097086,\n",
      "       0.00257669, 0.00254957, 0.00161957, 0.00207367, 0.00174124,\n",
      "       0.00157165, 0.00277097, 0.00164021, 0.00176806, 0.00151513,\n",
      "       0.0014964 , 0.00236282, 0.00150674, 0.00229006, 0.00107867,\n",
      "       0.0011397 , 0.0015332 , 0.00312192, 0.001238  , 0.00217065,\n",
      "       0.00118702, 0.00158743, 0.00173248, 0.0024355 , 0.00238199,\n",
      "       0.00226524, 0.00116539, 0.00185219, 0.00227692, 0.00177188,\n",
      "       0.0013609 , 0.00202094, 0.00207278, 0.00272322, 0.00159216,\n",
      "       0.00178453, 0.00099416, 0.00272842, 0.00234979, 0.00219644,\n",
      "       0.00112856, 0.00155646, 0.00166728, 0.00181648, 0.00177985,\n",
      "       0.00116429, 0.00139826, 0.00226797, 0.00115392, 0.00192284,\n",
      "       0.00225446, 0.00148942, 0.00206057, 0.00123023, 0.00170735,\n",
      "       0.00181817, 0.00148227, 0.00202526, 0.00147334, 0.00142247,\n",
      "       0.00267605, 0.00140539, 0.00125264, 0.00220151, 0.00156895,\n",
      "       0.00177358, 0.00101336, 0.0013353 , 0.00222943, 0.00129535,\n",
      "       0.00204611, 0.0012462 , 0.00236712, 0.00140617, 0.00234271,\n",
      "       0.00176189, 0.00105163, 0.00146156, 0.00121714, 0.00228581,\n",
      "       0.00125736, 0.00132433, 0.00214321, 0.0019888 , 0.0022761 ,\n",
      "       0.00185744, 0.00234433, 0.00222616, 0.00258564, 0.00128681,\n",
      "       0.00170685, 0.00113416, 0.00070857, 0.00156353, 0.00167632,\n",
      "       0.00170073, 0.001622  , 0.00193222, 0.00156967, 0.00138997,\n",
      "       0.00126125, 0.00130427, 0.00214932, 0.00122156, 0.00186121,\n",
      "       0.0016662 , 0.00198323, 0.00230367, 0.0013449 , 0.00250661,\n",
      "       0.00130641, 0.00098704, 0.00157198, 0.00183768, 0.0011305 ,\n",
      "       0.00230053, 0.00198157, 0.00284895, 0.00240824, 0.00182533,\n",
      "       0.00178954, 0.00271761, 0.00197145, 0.00245376, 0.002201  ,\n",
      "       0.00239124, 0.0021187 , 0.00247236, 0.00187234, 0.00125935,\n",
      "       0.00202784, 0.00153018, 0.00174787, 0.00200679, 0.00104744,\n",
      "       0.00231289, 0.00180834, 0.00210985, 0.00170736, 0.00125857,\n",
      "       0.00223078, 0.00182811, 0.00218925, 0.00220888, 0.00130606,\n",
      "       0.0011465 , 0.00244985, 0.00109253, 0.0018948 , 0.00151018,\n",
      "       0.00094367, 0.00194328, 0.00135474, 0.00167161, 0.00129089,\n",
      "       0.00181157, 0.00236354, 0.00211926, 0.00222796, 0.00253727,\n",
      "       0.00199611, 0.00137182, 0.00135873, 0.00116216, 0.00170001,\n",
      "       0.00209707, 0.00140244, 0.00110526, 0.00181203, 0.00234571,\n",
      "       0.00132625, 0.00117515, 0.00118417, 0.00157385, 0.00246155,\n",
      "       0.00142201, 0.00077438, 0.00117559, 0.00279196, 0.001342  ,\n",
      "       0.00102412, 0.00209696, 0.00251588, 0.00201233, 0.00144836,\n",
      "       0.00180894, 0.00121014, 0.00167346, 0.00166478, 0.00109272,\n",
      "       0.00139635, 0.00237114, 0.00186497, 0.00237106, 0.00211597,\n",
      "       0.00142852, 0.00115755, 0.00124162, 0.00202974, 0.00243086,\n",
      "       0.0018544 , 0.00244264, 0.00243793, 0.00128514, 0.00176888,\n",
      "       0.00113618, 0.00138459, 0.00130139, 0.00184655, 0.00141441,\n",
      "       0.0022832 , 0.00137643, 0.00122154, 0.00261054, 0.00184381,\n",
      "       0.00236986, 0.00126921, 0.00114908, 0.00166019, 0.00127016,\n",
      "       0.00219141, 0.00196997, 0.00138158, 0.00185743, 0.00253792,\n",
      "       0.00218609, 0.00223428, 0.00096976, 0.00173228, 0.00164263,\n",
      "       0.00288593, 0.0022669 , 0.00238227, 0.00149152, 0.00182738,\n",
      "       0.00131941, 0.00194742, 0.00105078, 0.00110703, 0.00225019,\n",
      "       0.00232157, 0.00097563, 0.002081  , 0.00130536, 0.00118852,\n",
      "       0.00127725], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'model_1/re_lu_7/Relu;model_1/batch_normalization_7/FusedBatchNormV3;model_1/depthwise_conv2d_3/depthwise;model_1/depthwise_conv2d_3/BiasAdd/ReadVariableOp;model_1/depthwise_conv2d_3/BiasAdd;model_1/depthwise_conv2d_4/depthwise', 'index': 10, 'shape': array([256], dtype=int32), 'shape_signature': array([256], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00060856, 0.00049846, 0.00052681, 0.00066691, 0.00046328,\n",
      "       0.00046843, 0.00070963, 0.00075677, 0.00046756, 0.0005215 ,\n",
      "       0.0007255 , 0.00089709, 0.00075784, 0.00034136, 0.0005446 ,\n",
      "       0.00042341, 0.0003556 , 0.00033439, 0.00048595, 0.00060831,\n",
      "       0.00047777, 0.00055513, 0.00060864, 0.00048323, 0.00078692,\n",
      "       0.00063074, 0.0004771 , 0.00049651, 0.0007437 , 0.00068977,\n",
      "       0.00058659, 0.0007141 , 0.00048299, 0.00051972, 0.00038913,\n",
      "       0.00041102, 0.00054065, 0.00057399, 0.00055371, 0.00069881,\n",
      "       0.00054834, 0.00066448, 0.00062215, 0.00057836, 0.00040046,\n",
      "       0.0007086 , 0.00045709, 0.0004983 , 0.000489  , 0.00052048,\n",
      "       0.00072544, 0.00115839, 0.00059895, 0.00048323, 0.00044727,\n",
      "       0.00056616, 0.00051549, 0.00067744, 0.00046376, 0.00037017,\n",
      "       0.00056943, 0.00052858, 0.00053809, 0.00049104, 0.00052391,\n",
      "       0.00052542, 0.00061557, 0.00065307, 0.00045307, 0.00051899,\n",
      "       0.00066398, 0.0008851 , 0.00065261, 0.00105198, 0.00053282,\n",
      "       0.00071996, 0.00044993, 0.00067665, 0.00095825, 0.00028467,\n",
      "       0.00058894, 0.00017761, 0.00052827, 0.00052123, 0.00061414,\n",
      "       0.00070389, 0.00051277, 0.00051952, 0.00039829, 0.00042544,\n",
      "       0.0004816 , 0.00099657, 0.0007192 , 0.00047903, 0.00056328,\n",
      "       0.00090989, 0.00054586, 0.00033434, 0.00068611, 0.00060337,\n",
      "       0.00042099, 0.00124256, 0.00033898, 0.0005807 , 0.00066133,\n",
      "       0.00048787, 0.00045155, 0.00042817, 0.00084205, 0.00038391,\n",
      "       0.0007874 , 0.00058559, 0.0006118 , 0.00081687, 0.00075833,\n",
      "       0.00053315, 0.00035265, 0.0004552 , 0.00049405, 0.00067723,\n",
      "       0.00067324, 0.00040044, 0.00050352, 0.0004382 , 0.00089348,\n",
      "       0.00032275, 0.0007699 , 0.00045971, 0.00039949, 0.00056102,\n",
      "       0.00070081, 0.00078789, 0.00076888, 0.00069278, 0.00081029,\n",
      "       0.00039636, 0.00069176, 0.00039901, 0.00078726, 0.00060621,\n",
      "       0.00062082, 0.00047442, 0.00043148, 0.0003325 , 0.00038941,\n",
      "       0.00065873, 0.00046309, 0.00049314, 0.0007215 , 0.00061008,\n",
      "       0.00077201, 0.00061808, 0.00048256, 0.00044238, 0.00054132,\n",
      "       0.00064265, 0.00057688, 0.00053989, 0.00049258, 0.0003984 ,\n",
      "       0.00043031, 0.00088597, 0.00047069, 0.00101164, 0.00030253,\n",
      "       0.00033989, 0.00060396, 0.00070069, 0.00061687, 0.00039169,\n",
      "       0.00059836, 0.00055648, 0.0004111 , 0.00058988, 0.00077525,\n",
      "       0.000663  , 0.00037964, 0.00048652, 0.00087321, 0.00062077,\n",
      "       0.00075574, 0.00064289, 0.00059343, 0.00045607, 0.00110972,\n",
      "       0.00059134, 0.00043571, 0.00063452, 0.00031603, 0.00049046,\n",
      "       0.00066657, 0.0005241 , 0.00052515, 0.00050313, 0.00093613,\n",
      "       0.00048603, 0.00059894, 0.00042638, 0.0007798 , 0.00072174,\n",
      "       0.0006039 , 0.00044139, 0.00048771, 0.00046878, 0.0004364 ,\n",
      "       0.00055016, 0.00073402, 0.00044478, 0.0005343 , 0.00054166,\n",
      "       0.00053516, 0.00066605, 0.00059096, 0.00048001, 0.00054615,\n",
      "       0.0007927 , 0.00042755, 0.00039712, 0.00055432, 0.0005354 ,\n",
      "       0.00052712, 0.00059382, 0.00026309, 0.0007544 , 0.00067686,\n",
      "       0.00050184, 0.00044835, 0.00080566, 0.00072143, 0.0011448 ,\n",
      "       0.0008323 , 0.00077894, 0.00061436, 0.00047622, 0.00053255,\n",
      "       0.00073554, 0.00128511, 0.00050481, 0.00073807, 0.00048895,\n",
      "       0.00094338, 0.00052627, 0.00052268, 0.00068316, 0.00064728,\n",
      "       0.00053328, 0.00054002, 0.0006284 , 0.00046946, 0.00043909,\n",
      "       0.0005076 , 0.00060345, 0.00049597, 0.0003775 , 0.00042411,\n",
      "       0.00054812], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'model_1/batch_normalization_7/FusedBatchNormV3;model_1/depthwise_conv2d_3/depthwise;model_1/depthwise_conv2d_3/BiasAdd/ReadVariableOp;model_1/depthwise_conv2d_3/BiasAdd;model_1/depthwise_conv2d_4/depthwise', 'index': 11, 'shape': array([  1,   3,   3, 256], dtype=int32), 'shape_signature': array([  1,   3,   3, 256], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00923912, 0.00756759, 0.0079979 , 0.01012499, 0.00703339,\n",
      "       0.00711168, 0.01077352, 0.01148913, 0.0070984 , 0.00791738,\n",
      "       0.01101443, 0.01361954, 0.01150549, 0.00518249, 0.00826803,\n",
      "       0.00642816, 0.00539871, 0.00507665, 0.00737762, 0.00923529,\n",
      "       0.00725343, 0.00842794, 0.00924032, 0.00733636, 0.01194688,\n",
      "       0.00957587, 0.00724332, 0.00753793, 0.01129069, 0.01047196,\n",
      "       0.0089056 , 0.01084145, 0.00733268, 0.00789032, 0.0059077 ,\n",
      "       0.00624005, 0.00820803, 0.00871429, 0.00840634, 0.01060918,\n",
      "       0.00832485, 0.01008799, 0.00944533, 0.00878056, 0.00607974,\n",
      "       0.01075783, 0.00693944, 0.00756521, 0.00742393, 0.00790193,\n",
      "       0.01101357, 0.0175866 , 0.00909324, 0.00733631, 0.00679042,\n",
      "       0.00859542, 0.00782613, 0.01028485, 0.0070408 , 0.00561985,\n",
      "       0.00864507, 0.00802489, 0.00816918, 0.00745492, 0.00795395,\n",
      "       0.00797683, 0.00934551, 0.0099148 , 0.00687847, 0.00787921,\n",
      "       0.0100805 , 0.01343753, 0.00990783, 0.0159711 , 0.00808924,\n",
      "       0.0109303 , 0.00683073, 0.01027279, 0.01454811, 0.00432187,\n",
      "       0.00894128, 0.00269651, 0.00802016, 0.0079132 , 0.00932382,\n",
      "       0.01068644, 0.00778482, 0.00788732, 0.00604675, 0.00645898,\n",
      "       0.00731158, 0.01512978, 0.01091878, 0.00727265, 0.00855165,\n",
      "       0.01381387, 0.00828715, 0.00507594, 0.01041639, 0.00916025,\n",
      "       0.00639143, 0.01886433, 0.00514633, 0.00881617, 0.01004027,\n",
      "       0.00740685, 0.0068554 , 0.00650049, 0.01278389, 0.00582853,\n",
      "       0.01195419, 0.00889031, 0.00928834, 0.01240165, 0.01151285,\n",
      "       0.00809419, 0.00535393, 0.00691072, 0.00750057, 0.01028162,\n",
      "       0.01022107, 0.00607937, 0.00764434, 0.00665273, 0.01356466,\n",
      "       0.00489988, 0.01168859, 0.0069792 , 0.00606501, 0.00851741,\n",
      "       0.01063958, 0.0119616 , 0.01167304, 0.01051773, 0.01230175,\n",
      "       0.00601749, 0.01050224, 0.00605776, 0.01195202, 0.00920342,\n",
      "       0.0094252 , 0.00720257, 0.00655062, 0.00504798, 0.00591201,\n",
      "       0.01000077, 0.00703053, 0.00748685, 0.01095376, 0.00926213,\n",
      "       0.01172053, 0.00938368, 0.00732614, 0.00671612, 0.00821821,\n",
      "       0.00975667, 0.00875811, 0.00819648, 0.00747822, 0.00604843,\n",
      "       0.00653286, 0.01345076, 0.00714593, 0.01535854, 0.00459291,\n",
      "       0.00516017, 0.00916926, 0.01063781, 0.0093652 , 0.00594661,\n",
      "       0.00908423, 0.00844845, 0.00624129, 0.00895553, 0.01176973,\n",
      "       0.01006551, 0.00576372, 0.00738635, 0.01325701, 0.00942448,\n",
      "       0.01147362, 0.00976033, 0.00900938, 0.00692399, 0.01684757,\n",
      "       0.00897767, 0.00661491, 0.00963326, 0.0047979 , 0.00744609,\n",
      "       0.01011972, 0.0079568 , 0.00797274, 0.00763845, 0.01421217,\n",
      "       0.00737884, 0.00909301, 0.00647323, 0.01183885, 0.01095741,\n",
      "       0.00916838, 0.00670119, 0.0074043 , 0.00711693, 0.00662531,\n",
      "       0.00835241, 0.01114382, 0.00675258, 0.00811173, 0.00822338,\n",
      "       0.00812472, 0.0101119 , 0.00897195, 0.00728749, 0.00829153,\n",
      "       0.01203462, 0.00649102, 0.00602905, 0.00841566, 0.00812837,\n",
      "       0.00800262, 0.00901524, 0.00399425, 0.01145319, 0.010276  ,\n",
      "       0.00761883, 0.00680681, 0.01223143, 0.01095266, 0.01738027,\n",
      "       0.01263594, 0.01182581, 0.00932707, 0.00722997, 0.00808508,\n",
      "       0.01116687, 0.01951046, 0.00766401, 0.01120536, 0.00742323,\n",
      "       0.01432222, 0.00798973, 0.0079352 , 0.01037172, 0.00982686,\n",
      "       0.00809619, 0.00819857, 0.00954031, 0.00712725, 0.00666624,\n",
      "       0.00770637, 0.00916144, 0.00752972, 0.00573123, 0.00643881,\n",
      "       0.00832143], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 3}, 'sparsity_parameters': {}}, {'name': 'model_1/re_lu_6/Relu;model_1/batch_normalization_6/FusedBatchNormV3;model_1/conv2d_3/BiasAdd/ReadVariableOp;model_1/conv2d_3/BiasAdd;model_1/depthwise_conv2d_4/depthwise;model_1/conv2d_3/Conv2D', 'index': 12, 'shape': array([256], dtype=int32), 'shape_signature': array([256], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00026181, 0.00040561, 0.00036455, 0.00025701, 0.00034856,\n",
      "       0.00030298, 0.00041241, 0.00035439, 0.00034138, 0.00032086,\n",
      "       0.00028326, 0.00022751, 0.00032925, 0.00031616, 0.00028884,\n",
      "       0.00032359, 0.00033352, 0.00034591, 0.00033521, 0.00041652,\n",
      "       0.00033831, 0.00029351, 0.00025716, 0.00035512, 0.00025888,\n",
      "       0.0002089 , 0.00029574, 0.00036556, 0.00034598, 0.00023946,\n",
      "       0.00027935, 0.00023707, 0.00036399, 0.0002142 , 0.00039148,\n",
      "       0.00046286, 0.00037211, 0.0003489 , 0.00036548, 0.00028692,\n",
      "       0.00029279, 0.00025327, 0.0002491 , 0.00028201, 0.00026194,\n",
      "       0.00030382, 0.00035165, 0.00031175, 0.00038328, 0.00030762,\n",
      "       0.00046264, 0.00022565, 0.0003509 , 0.00022188, 0.00032278,\n",
      "       0.00036386, 0.00030636, 0.00031458, 0.00026092, 0.00031802,\n",
      "       0.00020048, 0.0003557 , 0.00025709, 0.00034411, 0.00039651,\n",
      "       0.00035797, 0.00027662, 0.00023493, 0.00031863, 0.0005089 ,\n",
      "       0.00023138, 0.00022162, 0.00039143, 0.0003065 , 0.00029065,\n",
      "       0.00024186, 0.0004239 , 0.0003347 , 0.00026898, 0.00031685,\n",
      "       0.00031465, 0.00030476, 0.0003105 , 0.00027757, 0.0002734 ,\n",
      "       0.00029886, 0.00041018, 0.00033502, 0.00037681, 0.0003304 ,\n",
      "       0.00038319, 0.00022005, 0.00035427, 0.0003746 , 0.00028816,\n",
      "       0.00041733, 0.00039179, 0.00032164, 0.00034502, 0.00044014,\n",
      "       0.00041094, 0.00024482, 0.00031911, 0.00036872, 0.00038339,\n",
      "       0.00034585, 0.00035479, 0.00042349, 0.00027881, 0.00037577,\n",
      "       0.00024789, 0.00035547, 0.00025151, 0.00030813, 0.00035958,\n",
      "       0.00028397, 0.00041065, 0.00032627, 0.00034589, 0.00031039,\n",
      "       0.00024612, 0.00037075, 0.00036163, 0.00034377, 0.00032087,\n",
      "       0.00038601, 0.00023559, 0.00030199, 0.00041278, 0.00038351,\n",
      "       0.00023981, 0.00029212, 0.0002778 , 0.00031692, 0.00032342,\n",
      "       0.00030338, 0.00026672, 0.00038041, 0.00037605, 0.00026277,\n",
      "       0.00034056, 0.00043477, 0.00039937, 0.00043377, 0.00029472,\n",
      "       0.00027295, 0.00029579, 0.00028753, 0.00027431, 0.00027168,\n",
      "       0.00028057, 0.00029794, 0.0003761 , 0.0003516 , 0.00037815,\n",
      "       0.00028899, 0.00032451, 0.00036267, 0.00027747, 0.00036482,\n",
      "       0.0003324 , 0.00028776, 0.00037101, 0.00024742, 0.00046743,\n",
      "       0.00034983, 0.00025654, 0.00025253, 0.00023664, 0.00039395,\n",
      "       0.00028688, 0.00034336, 0.00028724, 0.00028158, 0.00023013,\n",
      "       0.00036068, 0.00056627, 0.00040346, 0.00031582, 0.00029138,\n",
      "       0.0003151 , 0.00031716, 0.00023284, 0.00033925, 0.00023931,\n",
      "       0.00034661, 0.00035075, 0.00028828, 0.00033343, 0.00030891,\n",
      "       0.00021398, 0.00036843, 0.00025387, 0.00033567, 0.00034854,\n",
      "       0.00035115, 0.00025261, 0.00025492, 0.00028143, 0.00036527,\n",
      "       0.00030624, 0.00022248, 0.00034324, 0.00033634, 0.00042122,\n",
      "       0.00033493, 0.00022954, 0.00037492, 0.00025531, 0.00026806,\n",
      "       0.00042201, 0.00029867, 0.00034655, 0.00031969, 0.00033019,\n",
      "       0.00025556, 0.00036446, 0.00032739, 0.00040995, 0.00032411,\n",
      "       0.00034076, 0.00039844, 0.00035955, 0.00025206, 0.00026565,\n",
      "       0.00030932, 0.00041987, 0.00027025, 0.0002857 , 0.00036666,\n",
      "       0.00038291, 0.00025585, 0.00040738, 0.00028502, 0.00036275,\n",
      "       0.00026003, 0.0002324 , 0.00030914, 0.00027965, 0.00027552,\n",
      "       0.00025959, 0.00023897, 0.00036856, 0.00028642, 0.00028165,\n",
      "       0.00027163, 0.00036661, 0.00029457, 0.00026681, 0.00034656,\n",
      "       0.00035073, 0.00030029, 0.00032285, 0.00042954, 0.00025857,\n",
      "       0.00036421], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'model_1/conv2d_3/Conv2D', 'index': 13, 'shape': array([256,   1,   1, 128], dtype=int32), 'shape_signature': array([256,   1,   1, 128], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00206457, 0.00319853, 0.00287478, 0.00202671, 0.00274867,\n",
      "       0.00238924, 0.00325222, 0.00279468, 0.00269209, 0.00253026,\n",
      "       0.00223371, 0.00179411, 0.00259641, 0.00249319, 0.00227773,\n",
      "       0.00255178, 0.00263006, 0.00272776, 0.00264338, 0.00328461,\n",
      "       0.00266786, 0.00231454, 0.00202792, 0.00280042, 0.00204149,\n",
      "       0.00164731, 0.00233212, 0.00288275, 0.00272834, 0.0018883 ,\n",
      "       0.00220287, 0.00186949, 0.00287036, 0.00168915, 0.00308711,\n",
      "       0.00365   , 0.00293437, 0.00275136, 0.00288207, 0.00226257,\n",
      "       0.00230888, 0.00199725, 0.00196439, 0.00222384, 0.00206562,\n",
      "       0.00239583, 0.00277304, 0.0024584 , 0.00302243, 0.00242586,\n",
      "       0.00364831, 0.00177939, 0.00276715, 0.0017497 , 0.00254541,\n",
      "       0.00286935, 0.00241587, 0.00248072, 0.00205757, 0.00250785,\n",
      "       0.00158095, 0.00280497, 0.00202734, 0.00271361, 0.00312684,\n",
      "       0.00282292, 0.00218134, 0.00185262, 0.00251264, 0.00401308,\n",
      "       0.00182459, 0.00174766, 0.00308677, 0.00241702, 0.00229198,\n",
      "       0.00190723, 0.00334281, 0.00263937, 0.00212115, 0.00249862,\n",
      "       0.00248128, 0.00240331, 0.0024485 , 0.0021889 , 0.00215594,\n",
      "       0.00235677, 0.00323461, 0.00264191, 0.00297141, 0.0026055 ,\n",
      "       0.00302172, 0.0017353 , 0.00279373, 0.002954  , 0.00227235,\n",
      "       0.00329098, 0.00308961, 0.00253638, 0.00272073, 0.00347085,\n",
      "       0.00324061, 0.00193059, 0.00251641, 0.00290768, 0.00302333,\n",
      "       0.00272732, 0.00279782, 0.00333957, 0.00219866, 0.00296323,\n",
      "       0.00195485, 0.0028032 , 0.00198334, 0.00242988, 0.00283555,\n",
      "       0.0022393 , 0.00323827, 0.00257289, 0.00272759, 0.00244771,\n",
      "       0.00194081, 0.00292369, 0.00285171, 0.0027109 , 0.0025303 ,\n",
      "       0.00304398, 0.0018578 , 0.00238145, 0.00325509, 0.0030243 ,\n",
      "       0.0018911 , 0.00230363, 0.0021907 , 0.00249915, 0.00255039,\n",
      "       0.00239237, 0.00210333, 0.00299985, 0.0029655 , 0.00207213,\n",
      "       0.00268559, 0.0034285 , 0.00314934, 0.0034206 , 0.00232408,\n",
      "       0.00215239, 0.00233253, 0.0022674 , 0.00216316, 0.00214243,\n",
      "       0.00221251, 0.00234951, 0.00296585, 0.00277267, 0.00298203,\n",
      "       0.00227892, 0.00255902, 0.00285993, 0.00218809, 0.00287693,\n",
      "       0.00262122, 0.00226925, 0.00292574, 0.00195112, 0.00368606,\n",
      "       0.00275867, 0.00202299, 0.00199144, 0.00186608, 0.00310664,\n",
      "       0.00226226, 0.00270765, 0.00226509, 0.00222046, 0.00181477,\n",
      "       0.00284423, 0.00446548, 0.00318159, 0.0024905 , 0.00229773,\n",
      "       0.00248482, 0.00250105, 0.00183612, 0.00267525, 0.00188713,\n",
      "       0.00273329, 0.00276591, 0.00227333, 0.00262935, 0.00243602,\n",
      "       0.00168738, 0.00290539, 0.00200196, 0.00264705, 0.00274848,\n",
      "       0.00276912, 0.00199204, 0.00201027, 0.0022193 , 0.00288043,\n",
      "       0.00241498, 0.00175447, 0.00270668, 0.00265231, 0.00332169,\n",
      "       0.0026412 , 0.00181012, 0.00295657, 0.00201332, 0.00211387,\n",
      "       0.00332786, 0.00235525, 0.0027328 , 0.00252103, 0.00260384,\n",
      "       0.00201528, 0.00287405, 0.00258172, 0.00323275, 0.00255588,\n",
      "       0.00268713, 0.003142  , 0.00283536, 0.00198769, 0.00209483,\n",
      "       0.0024392 , 0.00331102, 0.00213117, 0.002253  , 0.0028914 ,\n",
      "       0.00301957, 0.00201758, 0.00321254, 0.00224761, 0.00286056,\n",
      "       0.00205051, 0.00183265, 0.00243781, 0.00220524, 0.0021727 ,\n",
      "       0.00204707, 0.0018845 , 0.00290641, 0.00225866, 0.00222103,\n",
      "       0.002142  , 0.00289098, 0.00232291, 0.00210404, 0.00273288,\n",
      "       0.00276577, 0.00236804, 0.00254597, 0.00338728, 0.00203902,\n",
      "       0.00287213], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'model_1/re_lu_5/Relu;model_1/batch_normalization_5/FusedBatchNormV3;model_1/depthwise_conv2d_2/depthwise;model_1/depthwise_conv2d_2/BiasAdd/ReadVariableOp;model_1/depthwise_conv2d_2/BiasAdd', 'index': 14, 'shape': array([128], dtype=int32), 'shape_signature': array([128], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00052269, 0.0003363 , 0.00066362, 0.00051824, 0.00048319,\n",
      "       0.00069429, 0.00079006, 0.0003367 , 0.00062122, 0.00035025,\n",
      "       0.00048619, 0.00073783, 0.00052409, 0.00075899, 0.00063953,\n",
      "       0.00031823, 0.00042623, 0.00043317, 0.00037791, 0.00055778,\n",
      "       0.00054638, 0.0004598 , 0.00063344, 0.00059094, 0.00055507,\n",
      "       0.00091518, 0.00078849, 0.00049151, 0.00070688, 0.00075893,\n",
      "       0.00040568, 0.00081328, 0.0005854 , 0.00074736, 0.00037788,\n",
      "       0.00038027, 0.00093177, 0.0005964 , 0.00052701, 0.0005428 ,\n",
      "       0.00030215, 0.00034123, 0.0005847 , 0.00133709, 0.00060119,\n",
      "       0.00036668, 0.00043505, 0.0005715 , 0.00049625, 0.00113633,\n",
      "       0.00065994, 0.0005731 , 0.00045286, 0.00048935, 0.00039752,\n",
      "       0.00040325, 0.00067737, 0.00052508, 0.00079605, 0.00078403,\n",
      "       0.00037456, 0.00068197, 0.0005479 , 0.00057185, 0.00056622,\n",
      "       0.00073072, 0.00046869, 0.00027597, 0.00054751, 0.00064193,\n",
      "       0.00059233, 0.00052336, 0.00071666, 0.00050159, 0.00054837,\n",
      "       0.00051449, 0.00042351, 0.00054687, 0.0006142 , 0.00056067,\n",
      "       0.00056194, 0.00044066, 0.00033442, 0.00074249, 0.00056496,\n",
      "       0.00043123, 0.00064449, 0.00079832, 0.00034322, 0.00058538,\n",
      "       0.0011482 , 0.00078776, 0.00103998, 0.0010971 , 0.00045777,\n",
      "       0.00047193, 0.0005963 , 0.00055712, 0.00033011, 0.00088482,\n",
      "       0.00022518, 0.000656  , 0.00086733, 0.00035815, 0.00031322,\n",
      "       0.00059504, 0.00037423, 0.00065262, 0.00044873, 0.00040102,\n",
      "       0.00063279, 0.00062882, 0.00051326, 0.00050873, 0.00052526,\n",
      "       0.00057441, 0.00052593, 0.00053005, 0.00045503, 0.00055748,\n",
      "       0.00059842, 0.00052227, 0.00052005, 0.00062408, 0.00052092,\n",
      "       0.00042243, 0.0006756 , 0.0004081 ], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'model_1/batch_normalization_5/FusedBatchNormV3;model_1/depthwise_conv2d_2/depthwise;model_1/depthwise_conv2d_2/BiasAdd/ReadVariableOp;model_1/depthwise_conv2d_2/BiasAdd', 'index': 15, 'shape': array([  1,   3,   3, 128], dtype=int32), 'shape_signature': array([  1,   3,   3, 128], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00739953, 0.0047608 , 0.00939456, 0.00733647, 0.00684033,\n",
      "       0.00982876, 0.01118442, 0.00476649, 0.00879425, 0.00495827,\n",
      "       0.00688274, 0.01044516, 0.00741928, 0.01074467, 0.00905351,\n",
      "       0.00450501, 0.00603395, 0.00613216, 0.00534985, 0.00789616,\n",
      "       0.00773485, 0.00650914, 0.0089673 , 0.00836558, 0.00785787,\n",
      "       0.01295574, 0.0111622 , 0.00695804, 0.01000697, 0.01074385,\n",
      "       0.005743  , 0.01151322, 0.00828726, 0.01058   , 0.0053494 ,\n",
      "       0.00538328, 0.01319056, 0.00844291, 0.00746058, 0.00768415,\n",
      "       0.00427735, 0.00483064, 0.00827733, 0.01892851, 0.00851082,\n",
      "       0.00519096, 0.00615879, 0.00809046, 0.00702517, 0.01608647,\n",
      "       0.00934238, 0.00811307, 0.00641093, 0.00692751, 0.00562756,\n",
      "       0.00570867, 0.00958924, 0.00743324, 0.01126935, 0.01109912,\n",
      "       0.00530245, 0.00965429, 0.00775642, 0.00809538, 0.00801575,\n",
      "       0.01034447, 0.00663496, 0.00390674, 0.00775083, 0.0090875 ,\n",
      "       0.00838538, 0.00740894, 0.01014539, 0.00710072, 0.00776297,\n",
      "       0.00728342, 0.00599544, 0.00774181, 0.00869493, 0.00793716,\n",
      "       0.00795506, 0.00623823, 0.00473424, 0.0105111 , 0.00799784,\n",
      "       0.00610476, 0.00912375, 0.01130147, 0.00485883, 0.00828693,\n",
      "       0.01625451, 0.01115196, 0.01472248, 0.01553107, 0.00648047,\n",
      "       0.00668086, 0.00844149, 0.00788688, 0.0046732 , 0.01252592,\n",
      "       0.00318779, 0.00928665, 0.0122783 , 0.00507019, 0.00443416,\n",
      "       0.00842362, 0.0052978 , 0.00923881, 0.00635251, 0.00567699,\n",
      "       0.00895804, 0.00890185, 0.00726598, 0.00720182, 0.00743591,\n",
      "       0.00813162, 0.00744535, 0.00750362, 0.00644159, 0.00789191,\n",
      "       0.00847156, 0.00739352, 0.00736214, 0.00883483, 0.00737445,\n",
      "       0.00598007, 0.00956408, 0.00577733], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 3}, 'sparsity_parameters': {}}, {'name': 'model_1/re_lu_4/Relu;model_1/batch_normalization_4/FusedBatchNormV3;model_1/conv2d_2/BiasAdd/ReadVariableOp;model_1/conv2d_2/BiasAdd;model_1/depthwise_conv2d_2/depthwise;model_1/conv2d_2/Conv2D', 'index': 16, 'shape': array([128], dtype=int32), 'shape_signature': array([128], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00029903, 0.00039889, 0.0002839 , 0.00032045, 0.00039624,\n",
      "       0.00028719, 0.00028312, 0.00036164, 0.00034174, 0.00045194,\n",
      "       0.00034772, 0.00032775, 0.0003116 , 0.00024712, 0.0003122 ,\n",
      "       0.00032806, 0.00038137, 0.00042468, 0.00043301, 0.00039495,\n",
      "       0.00038335, 0.00030241, 0.00051099, 0.00031145, 0.00034764,\n",
      "       0.00033054, 0.00030474, 0.00036318, 0.00047477, 0.00025198,\n",
      "       0.0004896 , 0.00026948, 0.00039421, 0.0002815 , 0.00037321,\n",
      "       0.00036579, 0.00032445, 0.00037732, 0.00030549, 0.00041129,\n",
      "       0.00027616, 0.00051771, 0.00043913, 0.00030016, 0.00031478,\n",
      "       0.000364  , 0.00032409, 0.00042393, 0.00054419, 0.00028252,\n",
      "       0.00035171, 0.00033457, 0.00037935, 0.00034954, 0.00043182,\n",
      "       0.00030328, 0.00032783, 0.00052616, 0.00043998, 0.00034195,\n",
      "       0.00033918, 0.00031907, 0.00026996, 0.00041799, 0.00025607,\n",
      "       0.00027121, 0.00027234, 0.00037448, 0.0002803 , 0.00023304,\n",
      "       0.00038445, 0.00030519, 0.00041249, 0.00031339, 0.00034453,\n",
      "       0.00034537, 0.00037838, 0.00034756, 0.00039945, 0.00034301,\n",
      "       0.00039797, 0.00041362, 0.00035623, 0.00019976, 0.00037666,\n",
      "       0.00031512, 0.00042246, 0.00027812, 0.00030326, 0.00038688,\n",
      "       0.00020017, 0.00027485, 0.00033032, 0.00024864, 0.00039084,\n",
      "       0.00038564, 0.00034104, 0.00025337, 0.00033039, 0.00033763,\n",
      "       0.00053196, 0.00046838, 0.00026106, 0.00030262, 0.00032753,\n",
      "       0.00038694, 0.00046993, 0.00037717, 0.00037363, 0.00031536,\n",
      "       0.0003231 , 0.00037388, 0.0002754 , 0.00037601, 0.00025089,\n",
      "       0.00045786, 0.00034316, 0.0003807 , 0.00034346, 0.00027075,\n",
      "       0.00031423, 0.00039853, 0.00027184, 0.00048813, 0.00042069,\n",
      "       0.0003142 , 0.00034397, 0.00038823], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'model_1/conv2d_2/Conv2D', 'index': 17, 'shape': array([128,   1,   1,  64], dtype=int32), 'shape_signature': array([128,   1,   1,  64], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00251525, 0.00335517, 0.00238791, 0.00269538, 0.0033329 ,\n",
      "       0.00241564, 0.00238139, 0.00304184, 0.00287442, 0.00380136,\n",
      "       0.00292473, 0.00275675, 0.00262094, 0.00207854, 0.00262601,\n",
      "       0.00275935, 0.00320781, 0.00357204, 0.00364217, 0.00332198,\n",
      "       0.00322446, 0.00254367, 0.00429809, 0.00261968, 0.00292406,\n",
      "       0.00278021, 0.00256326, 0.00305479, 0.00399342, 0.00211948,\n",
      "       0.00411811, 0.00226666, 0.00331577, 0.00236778, 0.00313914,\n",
      "       0.00307678, 0.00272898, 0.00317372, 0.00256959, 0.00345945,\n",
      "       0.00232287, 0.00435458, 0.00369364, 0.00252468, 0.00264772,\n",
      "       0.00306166, 0.00272604, 0.0035658 , 0.00457729, 0.00237632,\n",
      "       0.00295832, 0.00281415, 0.00319083, 0.00294002, 0.00363214,\n",
      "       0.00255099, 0.00275749, 0.00442566, 0.0037008 , 0.00287619,\n",
      "       0.00285289, 0.0026838 , 0.00227066, 0.00351577, 0.00215388,\n",
      "       0.00228123, 0.00229069, 0.00314985, 0.00235765, 0.00196019,\n",
      "       0.00323372, 0.00256703, 0.00346956, 0.00263599, 0.00289788,\n",
      "       0.002905  , 0.00318267, 0.00292341, 0.0033599 , 0.00288512,\n",
      "       0.00334738, 0.00347903, 0.00299633, 0.00168025, 0.00316821,\n",
      "       0.00265056, 0.00355344, 0.00233931, 0.00255078, 0.00325414,\n",
      "       0.00168369, 0.00231182, 0.00277838, 0.00209139, 0.00328748,\n",
      "       0.00324373, 0.00286855, 0.00213117, 0.00277896, 0.00283991,\n",
      "       0.0044744 , 0.00393962, 0.0021958 , 0.0025454 , 0.00275494,\n",
      "       0.00325462, 0.0039527 , 0.00317242, 0.0031427 , 0.00265256,\n",
      "       0.00271764, 0.00314483, 0.00231644, 0.0031627 , 0.00211027,\n",
      "       0.00385119, 0.00288643, 0.00320214, 0.00288894, 0.00227732,\n",
      "       0.00264304, 0.00335215, 0.0022865 , 0.00410576, 0.0035385 ,\n",
      "       0.00264284, 0.00289318, 0.00326548], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'model_1/re_lu_3/Relu;model_1/batch_normalization_3/FusedBatchNormV3;model_1/depthwise_conv2d_1/depthwise;model_1/depthwise_conv2d_1/BiasAdd/ReadVariableOp;model_1/depthwise_conv2d_1/BiasAdd', 'index': 18, 'shape': array([64], dtype=int32), 'shape_signature': array([64], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00071635, 0.00063724, 0.00030234, 0.00059724, 0.00065253,\n",
      "       0.00052217, 0.00046826, 0.00067016, 0.00106333, 0.00050995,\n",
      "       0.00079082, 0.00099374, 0.00128645, 0.00052284, 0.0005574 ,\n",
      "       0.00059865, 0.0004604 , 0.00072364, 0.00050144, 0.00051941,\n",
      "       0.00060912, 0.0007044 , 0.00074338, 0.00056717, 0.000369  ,\n",
      "       0.00094107, 0.00057117, 0.00042599, 0.00051681, 0.00118896,\n",
      "       0.00035288, 0.00066817, 0.00045357, 0.00097818, 0.00111693,\n",
      "       0.00055764, 0.00070869, 0.0004879 , 0.00059748, 0.00066079,\n",
      "       0.00042635, 0.00066637, 0.0004329 , 0.00022759, 0.00044734,\n",
      "       0.00065292, 0.00056568, 0.00088967, 0.00136432, 0.00066598,\n",
      "       0.00034386, 0.00038201, 0.00063052, 0.00094562, 0.00047677,\n",
      "       0.00068856, 0.00046035, 0.00096496, 0.00041916, 0.00036378,\n",
      "       0.00103182, 0.00054928, 0.00053378, 0.00072427], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "      dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'model_1/batch_normalization_3/FusedBatchNormV3;model_1/depthwise_conv2d_1/depthwise;model_1/depthwise_conv2d_1/BiasAdd/ReadVariableOp;model_1/depthwise_conv2d_1/BiasAdd', 'index': 19, 'shape': array([ 1,  3,  3, 64], dtype=int32), 'shape_signature': array([ 1,  3,  3, 64], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00906309, 0.00806218, 0.00382518, 0.00755609, 0.00825562,\n",
      "       0.00660641, 0.00592434, 0.00847867, 0.01345302, 0.00645175,\n",
      "       0.01000529, 0.01257255, 0.0162759 , 0.0066148 , 0.0070521 ,\n",
      "       0.00757392, 0.00582484, 0.00915538, 0.00634409, 0.00657149,\n",
      "       0.00770647, 0.00891194, 0.00940506, 0.00717575, 0.00466847,\n",
      "       0.01190624, 0.00722635, 0.00538949, 0.0065386 , 0.01504245,\n",
      "       0.0044645 , 0.00845359, 0.00573851, 0.01237576, 0.0141312 ,\n",
      "       0.00705515, 0.00896619, 0.00617275, 0.00755923, 0.00836023,\n",
      "       0.00539403, 0.00843074, 0.00547701, 0.00287946, 0.00565965,\n",
      "       0.00826061, 0.00715691, 0.01125587, 0.01726103, 0.00842584,\n",
      "       0.00435048, 0.00483313, 0.00797722, 0.01196377, 0.00603192,\n",
      "       0.00871151, 0.00582422, 0.01220842, 0.00530311, 0.00460248,\n",
      "       0.01305441, 0.00694933, 0.00675332, 0.00916328], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "      dtype=int32), 'quantized_dimension': 3}, 'sparsity_parameters': {}}, {'name': 'model_1/re_lu_2/Relu;model_1/batch_normalization_2/FusedBatchNormV3;model_1/conv2d_1/BiasAdd/ReadVariableOp;model_1/conv2d_1/BiasAdd;model_1/depthwise_conv2d_1/depthwise;model_1/conv2d_1/Conv2D', 'index': 20, 'shape': array([64], dtype=int32), 'shape_signature': array([64], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00017387, 0.0003871 , 0.00032202, 0.00038715, 0.00040387,\n",
      "       0.00032153, 0.00026171, 0.00029665, 0.00027759, 0.00028369,\n",
      "       0.00026713, 0.00024136, 0.00019204, 0.00029697, 0.00040443,\n",
      "       0.00036015, 0.00035126, 0.00031903, 0.00051305, 0.00034351,\n",
      "       0.00041847, 0.00036767, 0.0003403 , 0.00026844, 0.00034136,\n",
      "       0.00028269, 0.00033672, 0.00032507, 0.00035644, 0.00025284,\n",
      "       0.0003053 , 0.00029261, 0.00046249, 0.00026634, 0.00026119,\n",
      "       0.00030916, 0.00041283, 0.0003754 , 0.0002831 , 0.00029936,\n",
      "       0.00039977, 0.00028873, 0.00035354, 0.00037424, 0.0004144 ,\n",
      "       0.00021474, 0.00042196, 0.00038346, 0.00024858, 0.00046144,\n",
      "       0.00034555, 0.00041   , 0.00036866, 0.00025365, 0.00042803,\n",
      "       0.00043925, 0.00029167, 0.00029298, 0.00046343, 0.0003701 ,\n",
      "       0.00029366, 0.00041459, 0.00035344, 0.00027538], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "      dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'model_1/conv2d_1/Conv2D', 'index': 21, 'shape': array([64,  1,  1, 32], dtype=int32), 'shape_signature': array([64,  1,  1, 32], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00191148, 0.00425556, 0.00354015, 0.00425611, 0.0044399 ,\n",
      "       0.00353479, 0.00287707, 0.00326125, 0.00305166, 0.00311872,\n",
      "       0.00293668, 0.00265338, 0.00211121, 0.00326471, 0.00444614,\n",
      "       0.0039593 , 0.00386155, 0.00350724, 0.00564027, 0.0037764 ,\n",
      "       0.00460049, 0.00404199, 0.00374115, 0.00295109, 0.00375273,\n",
      "       0.00310772, 0.00370177, 0.00357369, 0.00391856, 0.00277966,\n",
      "       0.00335632, 0.00321677, 0.00508434, 0.00292799, 0.00287138,\n",
      "       0.00339871, 0.00453845, 0.00412693, 0.00311222, 0.00329106,\n",
      "       0.00439486, 0.00317415, 0.00388661, 0.0041142 , 0.00455576,\n",
      "       0.00236075, 0.00463886, 0.00421557, 0.00273278, 0.00507289,\n",
      "       0.00379884, 0.00450732, 0.00405283, 0.00278849, 0.0047055 ,\n",
      "       0.00482895, 0.00320647, 0.00322085, 0.00509471, 0.00406865,\n",
      "       0.00322833, 0.00455783, 0.00388552, 0.00302735], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "      dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'model_1/re_lu_1/Relu;model_1/batch_normalization_1/FusedBatchNormV3;model_1/depthwise_conv2d/depthwise;model_1/depthwise_conv2d/BiasAdd/ReadVariableOp;model_1/depthwise_conv2d/BiasAdd', 'index': 22, 'shape': array([32], dtype=int32), 'shape_signature': array([32], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00054194, 0.00033537, 0.00060719, 0.00033744, 0.00047457,\n",
      "       0.00068526, 0.00059662, 0.00092869, 0.0006139 , 0.00049429,\n",
      "       0.00060863, 0.00056389, 0.00018777, 0.00049938, 0.00049668,\n",
      "       0.00038316, 0.00025298, 0.00079063, 0.00061021, 0.00054054,\n",
      "       0.00056438, 0.00045012, 0.00071828, 0.00052943, 0.00025342,\n",
      "       0.00085506, 0.00047924, 0.00032175, 0.00062538, 0.00034749,\n",
      "       0.00023056, 0.00039982], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'model_1/batch_normalization_1/FusedBatchNormV3;model_1/depthwise_conv2d/depthwise;model_1/depthwise_conv2d/BiasAdd/ReadVariableOp;model_1/depthwise_conv2d/BiasAdd', 'index': 23, 'shape': array([ 1,  3,  3, 32], dtype=int32), 'shape_signature': array([ 1,  3,  3, 32], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.0127499 , 0.00789007, 0.0142851 , 0.00793873, 0.01116499,\n",
      "       0.01612164, 0.01403621, 0.02184867, 0.01444278, 0.01162881,\n",
      "       0.0143189 , 0.01326636, 0.00441758, 0.0117487 , 0.01168508,\n",
      "       0.00901439, 0.00595181, 0.01860062, 0.01435607, 0.01271692,\n",
      "       0.01327781, 0.0105898 , 0.01689851, 0.01245566, 0.00596216,\n",
      "       0.02011655, 0.01127475, 0.00756952, 0.01471283, 0.00817531,\n",
      "       0.0054242 , 0.00940642], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 3}, 'sparsity_parameters': {}}, {'name': 'model_1/re_lu/Relu;model_1/batch_normalization/FusedBatchNormV3;model_1/conv2d/BiasAdd/ReadVariableOp;model_1/conv2d/BiasAdd;model_1/depthwise_conv2d/depthwise;model_1/conv2d/Conv2D', 'index': 24, 'shape': array([32], dtype=int32), 'shape_signature': array([32], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([1.05194580e-04, 3.01953605e-05, 8.07464021e-05, 1.54354260e-04,\n",
      "       6.70156878e-05, 4.15773538e-05, 8.12436192e-05, 4.01659090e-05,\n",
      "       1.14354516e-04, 1.10710382e-04, 4.70816776e-05, 1.01730591e-04,\n",
      "       4.47019556e-05, 1.04371524e-04, 6.30063223e-05, 1.62069147e-04,\n",
      "       5.34186729e-05, 5.21965776e-05, 1.02424099e-04, 2.83348872e-05,\n",
      "       1.39457727e-04, 4.41880329e-05, 4.72981337e-05, 7.81030467e-05,\n",
      "       7.32482367e-05, 4.02279729e-05, 5.60788249e-05, 2.13609692e-05,\n",
      "       1.00135709e-04, 1.15024377e-04, 1.13549060e-04, 1.30545552e-04],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'model_1/conv2d/Conv2D', 'index': 25, 'shape': array([32,  3,  3,  1], dtype=int32), 'shape_signature': array([32,  3,  3,  1], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.02682462, 0.00769982, 0.02059033, 0.03936033, 0.017089  ,\n",
      "       0.01060222, 0.02071712, 0.01024231, 0.0291604 , 0.02823115,\n",
      "       0.01200583, 0.0259413 , 0.011399  , 0.02661474, 0.01606661,\n",
      "       0.04132763, 0.01362176, 0.01331013, 0.02611814, 0.0072254 ,\n",
      "       0.03556172, 0.01126795, 0.01206102, 0.01991628, 0.0186783 ,\n",
      "       0.01025813, 0.0143001 , 0.00544705, 0.0255346 , 0.02933121,\n",
      "       0.02895501, 0.03328911], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'tfl.quantize', 'index': 26, 'shape': array([  1, 256, 256,   1], dtype=int32), 'shape_signature': array([ -1, 256, 256,   1], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.003921568859368563, -128), 'quantization_parameters': {'scales': array([0.00392157], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'model_1/re_lu/Relu;model_1/batch_normalization/FusedBatchNormV3;model_1/conv2d/BiasAdd/ReadVariableOp;model_1/conv2d/BiasAdd;model_1/depthwise_conv2d/depthwise;model_1/conv2d/Conv2D1', 'index': 27, 'shape': array([  1, 128, 128,  32], dtype=int32), 'shape_signature': array([ -1, 128, 128,  32], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0425054132938385, -128), 'quantization_parameters': {'scales': array([0.04250541], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'model_1/re_lu_1/Relu;model_1/batch_normalization_1/FusedBatchNormV3;model_1/depthwise_conv2d/depthwise;model_1/depthwise_conv2d/BiasAdd/ReadVariableOp;model_1/depthwise_conv2d/BiasAdd1', 'index': 28, 'shape': array([  1, 128, 128,  32], dtype=int32), 'shape_signature': array([ -1, 128, 128,  32], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.09096262603998184, -128), 'quantization_parameters': {'scales': array([0.09096263], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'model_1/re_lu_2/Relu;model_1/batch_normalization_2/FusedBatchNormV3;model_1/conv2d_1/BiasAdd/ReadVariableOp;model_1/conv2d_1/BiasAdd;model_1/depthwise_conv2d_1/depthwise;model_1/conv2d_1/Conv2D1', 'index': 29, 'shape': array([  1, 128, 128,  64], dtype=int32), 'shape_signature': array([ -1, 128, 128,  64], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0790402814745903, -128), 'quantization_parameters': {'scales': array([0.07904028], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'model_1/re_lu_3/Relu;model_1/batch_normalization_3/FusedBatchNormV3;model_1/depthwise_conv2d_1/depthwise;model_1/depthwise_conv2d_1/BiasAdd/ReadVariableOp;model_1/depthwise_conv2d_1/BiasAdd1', 'index': 30, 'shape': array([ 1, 64, 64, 64], dtype=int32), 'shape_signature': array([-1, 64, 64, 64], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.118888720870018, -128), 'quantization_parameters': {'scales': array([0.11888872], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'model_1/re_lu_4/Relu;model_1/batch_normalization_4/FusedBatchNormV3;model_1/conv2d_2/BiasAdd/ReadVariableOp;model_1/conv2d_2/BiasAdd;model_1/depthwise_conv2d_2/depthwise;model_1/conv2d_2/Conv2D1', 'index': 31, 'shape': array([  1,  64,  64, 128], dtype=int32), 'shape_signature': array([ -1,  64,  64, 128], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.07063888758420944, -128), 'quantization_parameters': {'scales': array([0.07063889], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'model_1/re_lu_5/Relu;model_1/batch_normalization_5/FusedBatchNormV3;model_1/depthwise_conv2d_2/depthwise;model_1/depthwise_conv2d_2/BiasAdd/ReadVariableOp;model_1/depthwise_conv2d_2/BiasAdd1', 'index': 32, 'shape': array([  1,  32,  32, 128], dtype=int32), 'shape_signature': array([ -1,  32,  32, 128], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.12681016325950623, -128), 'quantization_parameters': {'scales': array([0.12681016], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'model_1/re_lu_6/Relu;model_1/batch_normalization_6/FusedBatchNormV3;model_1/conv2d_3/BiasAdd/ReadVariableOp;model_1/conv2d_3/BiasAdd;model_1/depthwise_conv2d_4/depthwise;model_1/conv2d_3/Conv2D1', 'index': 33, 'shape': array([  1,  32,  32, 256], dtype=int32), 'shape_signature': array([ -1,  32,  32, 256], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.06586799770593643, -128), 'quantization_parameters': {'scales': array([0.065868], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'model_1/re_lu_7/Relu;model_1/batch_normalization_7/FusedBatchNormV3;model_1/depthwise_conv2d_3/depthwise;model_1/depthwise_conv2d_3/BiasAdd/ReadVariableOp;model_1/depthwise_conv2d_3/BiasAdd;model_1/depthwise_conv2d_4/depthwise1', 'index': 34, 'shape': array([  1,  32,  32, 256], dtype=int32), 'shape_signature': array([ -1,  32,  32, 256], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.09238358587026596, -128), 'quantization_parameters': {'scales': array([0.09238359], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'model_1/re_lu_8/Relu;model_1/batch_normalization_8/FusedBatchNormV3;model_1/conv2d_4/BiasAdd/ReadVariableOp;model_1/conv2d_4/BiasAdd;model_1/depthwise_conv2d_4/depthwise;model_1/conv2d_4/Conv2D1', 'index': 35, 'shape': array([  1,  32,  32, 256], dtype=int32), 'shape_signature': array([ -1,  32,  32, 256], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0483926422894001, -128), 'quantization_parameters': {'scales': array([0.04839264], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'model_1/re_lu_9/Relu;model_1/batch_normalization_9/FusedBatchNormV3;model_1/depthwise_conv2d_4/depthwise;model_1/depthwise_conv2d_4/BiasAdd/ReadVariableOp;model_1/depthwise_conv2d_4/BiasAdd1', 'index': 36, 'shape': array([  1,  32,  32, 256], dtype=int32), 'shape_signature': array([ -1,  32,  32, 256], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.06697415560483932, -128), 'quantization_parameters': {'scales': array([0.06697416], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'model_1/re_lu_10/Relu;model_1/batch_normalization_10/FusedBatchNormV3;model_1/conv2d_5/BiasAdd/ReadVariableOp;model_1/conv2d_5/BiasAdd;model_1/conv2d_5/Conv2D1', 'index': 37, 'shape': array([  1,  32,  32, 512], dtype=int32), 'shape_signature': array([ -1,  32,  32, 512], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.052679404616355896, -128), 'quantization_parameters': {'scales': array([0.0526794], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'model_1/global_average_pooling2d_1/Mean', 'index': 38, 'shape': array([  1, 512], dtype=int32), 'shape_signature': array([ -1, 512], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.004618079401552677, -128), 'quantization_parameters': {'scales': array([0.00461808], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'model_1/dense_1/MatMul;model_1/dense_1/BiasAdd', 'index': 39, 'shape': array([1, 1], dtype=int32), 'shape_signature': array([-1,  1], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.14973488450050354, -41), 'quantization_parameters': {'scales': array([0.14973488], dtype=float32), 'zero_points': array([-41], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:01', 'index': 40, 'shape': array([1, 1], dtype=int32), 'shape_signature': array([-1,  1], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.00390625, -128), 'quantization_parameters': {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:0', 'index': 41, 'shape': array([1, 1], dtype=int32), 'shape_signature': array([-1,  1], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
      "serving_default_input_2:0\n",
      "model_1/global_average_pooling2d_1/Mean/reduction_indices\n",
      "model_1/dense_1/BiasAdd/ReadVariableOp\n",
      "model_1/dense_1/MatMul\n",
      "model_1/re_lu_10/Relu;model_1/batch_normalization_10/FusedBatchNormV3;model_1/conv2d_5/BiasAdd/ReadVariableOp;model_1/conv2d_5/BiasAdd;model_1/conv2d_5/Conv2D\n",
      "model_1/conv2d_5/Conv2D\n",
      "model_1/re_lu_9/Relu;model_1/batch_normalization_9/FusedBatchNormV3;model_1/depthwise_conv2d_4/depthwise;model_1/depthwise_conv2d_4/BiasAdd/ReadVariableOp;model_1/depthwise_conv2d_4/BiasAdd\n",
      "model_1/batch_normalization_9/FusedBatchNormV3;model_1/depthwise_conv2d_4/depthwise;model_1/depthwise_conv2d_4/BiasAdd/ReadVariableOp;model_1/depthwise_conv2d_4/BiasAdd\n",
      "model_1/re_lu_8/Relu;model_1/batch_normalization_8/FusedBatchNormV3;model_1/conv2d_4/BiasAdd/ReadVariableOp;model_1/conv2d_4/BiasAdd;model_1/depthwise_conv2d_4/depthwise;model_1/conv2d_4/Conv2D\n",
      "model_1/conv2d_4/Conv2D\n",
      "model_1/re_lu_7/Relu;model_1/batch_normalization_7/FusedBatchNormV3;model_1/depthwise_conv2d_3/depthwise;model_1/depthwise_conv2d_3/BiasAdd/ReadVariableOp;model_1/depthwise_conv2d_3/BiasAdd;model_1/depthwise_conv2d_4/depthwise\n",
      "model_1/batch_normalization_7/FusedBatchNormV3;model_1/depthwise_conv2d_3/depthwise;model_1/depthwise_conv2d_3/BiasAdd/ReadVariableOp;model_1/depthwise_conv2d_3/BiasAdd;model_1/depthwise_conv2d_4/depthwise\n",
      "model_1/re_lu_6/Relu;model_1/batch_normalization_6/FusedBatchNormV3;model_1/conv2d_3/BiasAdd/ReadVariableOp;model_1/conv2d_3/BiasAdd;model_1/depthwise_conv2d_4/depthwise;model_1/conv2d_3/Conv2D\n",
      "model_1/conv2d_3/Conv2D\n",
      "model_1/re_lu_5/Relu;model_1/batch_normalization_5/FusedBatchNormV3;model_1/depthwise_conv2d_2/depthwise;model_1/depthwise_conv2d_2/BiasAdd/ReadVariableOp;model_1/depthwise_conv2d_2/BiasAdd\n",
      "model_1/batch_normalization_5/FusedBatchNormV3;model_1/depthwise_conv2d_2/depthwise;model_1/depthwise_conv2d_2/BiasAdd/ReadVariableOp;model_1/depthwise_conv2d_2/BiasAdd\n",
      "model_1/re_lu_4/Relu;model_1/batch_normalization_4/FusedBatchNormV3;model_1/conv2d_2/BiasAdd/ReadVariableOp;model_1/conv2d_2/BiasAdd;model_1/depthwise_conv2d_2/depthwise;model_1/conv2d_2/Conv2D\n",
      "model_1/conv2d_2/Conv2D\n",
      "model_1/re_lu_3/Relu;model_1/batch_normalization_3/FusedBatchNormV3;model_1/depthwise_conv2d_1/depthwise;model_1/depthwise_conv2d_1/BiasAdd/ReadVariableOp;model_1/depthwise_conv2d_1/BiasAdd\n",
      "model_1/batch_normalization_3/FusedBatchNormV3;model_1/depthwise_conv2d_1/depthwise;model_1/depthwise_conv2d_1/BiasAdd/ReadVariableOp;model_1/depthwise_conv2d_1/BiasAdd\n",
      "model_1/re_lu_2/Relu;model_1/batch_normalization_2/FusedBatchNormV3;model_1/conv2d_1/BiasAdd/ReadVariableOp;model_1/conv2d_1/BiasAdd;model_1/depthwise_conv2d_1/depthwise;model_1/conv2d_1/Conv2D\n",
      "model_1/conv2d_1/Conv2D\n",
      "model_1/re_lu_1/Relu;model_1/batch_normalization_1/FusedBatchNormV3;model_1/depthwise_conv2d/depthwise;model_1/depthwise_conv2d/BiasAdd/ReadVariableOp;model_1/depthwise_conv2d/BiasAdd\n",
      "model_1/batch_normalization_1/FusedBatchNormV3;model_1/depthwise_conv2d/depthwise;model_1/depthwise_conv2d/BiasAdd/ReadVariableOp;model_1/depthwise_conv2d/BiasAdd\n",
      "model_1/re_lu/Relu;model_1/batch_normalization/FusedBatchNormV3;model_1/conv2d/BiasAdd/ReadVariableOp;model_1/conv2d/BiasAdd;model_1/depthwise_conv2d/depthwise;model_1/conv2d/Conv2D\n",
      "model_1/conv2d/Conv2D\n",
      "tfl.quantize\n",
      "model_1/re_lu/Relu;model_1/batch_normalization/FusedBatchNormV3;model_1/conv2d/BiasAdd/ReadVariableOp;model_1/conv2d/BiasAdd;model_1/depthwise_conv2d/depthwise;model_1/conv2d/Conv2D1\n",
      "model_1/re_lu_1/Relu;model_1/batch_normalization_1/FusedBatchNormV3;model_1/depthwise_conv2d/depthwise;model_1/depthwise_conv2d/BiasAdd/ReadVariableOp;model_1/depthwise_conv2d/BiasAdd1\n",
      "model_1/re_lu_2/Relu;model_1/batch_normalization_2/FusedBatchNormV3;model_1/conv2d_1/BiasAdd/ReadVariableOp;model_1/conv2d_1/BiasAdd;model_1/depthwise_conv2d_1/depthwise;model_1/conv2d_1/Conv2D1\n",
      "model_1/re_lu_3/Relu;model_1/batch_normalization_3/FusedBatchNormV3;model_1/depthwise_conv2d_1/depthwise;model_1/depthwise_conv2d_1/BiasAdd/ReadVariableOp;model_1/depthwise_conv2d_1/BiasAdd1\n",
      "model_1/re_lu_4/Relu;model_1/batch_normalization_4/FusedBatchNormV3;model_1/conv2d_2/BiasAdd/ReadVariableOp;model_1/conv2d_2/BiasAdd;model_1/depthwise_conv2d_2/depthwise;model_1/conv2d_2/Conv2D1\n",
      "model_1/re_lu_5/Relu;model_1/batch_normalization_5/FusedBatchNormV3;model_1/depthwise_conv2d_2/depthwise;model_1/depthwise_conv2d_2/BiasAdd/ReadVariableOp;model_1/depthwise_conv2d_2/BiasAdd1\n",
      "model_1/re_lu_6/Relu;model_1/batch_normalization_6/FusedBatchNormV3;model_1/conv2d_3/BiasAdd/ReadVariableOp;model_1/conv2d_3/BiasAdd;model_1/depthwise_conv2d_4/depthwise;model_1/conv2d_3/Conv2D1\n",
      "model_1/re_lu_7/Relu;model_1/batch_normalization_7/FusedBatchNormV3;model_1/depthwise_conv2d_3/depthwise;model_1/depthwise_conv2d_3/BiasAdd/ReadVariableOp;model_1/depthwise_conv2d_3/BiasAdd;model_1/depthwise_conv2d_4/depthwise1\n",
      "model_1/re_lu_8/Relu;model_1/batch_normalization_8/FusedBatchNormV3;model_1/conv2d_4/BiasAdd/ReadVariableOp;model_1/conv2d_4/BiasAdd;model_1/depthwise_conv2d_4/depthwise;model_1/conv2d_4/Conv2D1\n",
      "model_1/re_lu_9/Relu;model_1/batch_normalization_9/FusedBatchNormV3;model_1/depthwise_conv2d_4/depthwise;model_1/depthwise_conv2d_4/BiasAdd/ReadVariableOp;model_1/depthwise_conv2d_4/BiasAdd1\n",
      "model_1/re_lu_10/Relu;model_1/batch_normalization_10/FusedBatchNormV3;model_1/conv2d_5/BiasAdd/ReadVariableOp;model_1/conv2d_5/BiasAdd;model_1/conv2d_5/Conv2D1\n",
      "model_1/global_average_pooling2d_1/Mean\n",
      "model_1/dense_1/MatMul;model_1/dense_1/BiasAdd\n",
      "StatefulPartitionedCall:01\n",
      "StatefulPartitionedCall:0\n"
     ]
    }
   ],
   "source": [
    "interpreter_quant = tf.lite.Interpreter(model_path=\"person_detection_quantized.tflite\")\n",
    "# Get input and output tensors.\n",
    "input_details = interpreter_quant.get_input_details()\n",
    "output_details = interpreter_quant.get_output_details()\n",
    "print(input_details, output_details)\n",
    "print(\"tensor details\")\n",
    "print(interpreter_quant.get_tensor_details())\n",
    "for op in interpreter_quant.get_tensor_details():\n",
    "    print(op['name'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'serving_default_input_2:0', 'index': 0, 'shape': array([  1, 256, 256,   1], dtype=int32), 'shape_signature': array([ -1, 256, 256,   1], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}] [{'name': 'StatefulPartitionedCall:0', 'index': 39, 'shape': array([1, 1], dtype=int32), 'shape_signature': array([-1,  1], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
      "tensor details\n",
      "[{'name': 'serving_default_input_2:0', 'index': 0, 'shape': array([  1, 256, 256,   1], dtype=int32), 'shape_signature': array([ -1, 256, 256,   1], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'model_1/re_lu_1/Relu;model_1/batch_normalization_1/FusedBatchNormV3;model_1/depthwise_conv2d/depthwise;model_1/depthwise_conv2d/BiasAdd/ReadVariableOp;model_1/depthwise_conv2d/BiasAdd', 'index': 1, 'shape': array([32], dtype=int32), 'shape_signature': array([32], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'model_1/re_lu_3/Relu;model_1/batch_normalization_3/FusedBatchNormV3;model_1/depthwise_conv2d_1/depthwise;model_1/depthwise_conv2d_1/BiasAdd/ReadVariableOp;model_1/depthwise_conv2d_1/BiasAdd', 'index': 2, 'shape': array([64], dtype=int32), 'shape_signature': array([64], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'model_1/re_lu_5/Relu;model_1/batch_normalization_5/FusedBatchNormV3;model_1/depthwise_conv2d_2/depthwise;model_1/depthwise_conv2d_2/BiasAdd/ReadVariableOp;model_1/depthwise_conv2d_2/BiasAdd', 'index': 3, 'shape': array([128], dtype=int32), 'shape_signature': array([128], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'model_1/re_lu_7/Relu;model_1/batch_normalization_7/FusedBatchNormV3;model_1/depthwise_conv2d_3/depthwise;model_1/depthwise_conv2d_3/BiasAdd/ReadVariableOp;model_1/depthwise_conv2d_3/BiasAdd;model_1/depthwise_conv2d_4/depthwise', 'index': 4, 'shape': array([256], dtype=int32), 'shape_signature': array([256], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'model_1/re_lu_9/Relu;model_1/batch_normalization_9/FusedBatchNormV3;model_1/depthwise_conv2d_4/depthwise;model_1/depthwise_conv2d_4/BiasAdd/ReadVariableOp;model_1/depthwise_conv2d_4/BiasAdd', 'index': 5, 'shape': array([256], dtype=int32), 'shape_signature': array([256], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'model_1/re_lu/Relu;model_1/batch_normalization/FusedBatchNormV3;model_1/conv2d/BiasAdd/ReadVariableOp;model_1/conv2d/BiasAdd;model_1/depthwise_conv2d/depthwise;model_1/conv2d/Conv2D', 'index': 6, 'shape': array([32], dtype=int32), 'shape_signature': array([32], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'model_1/batch_normalization_1/FusedBatchNormV3;model_1/depthwise_conv2d/depthwise;model_1/depthwise_conv2d/BiasAdd/ReadVariableOp;model_1/depthwise_conv2d/BiasAdd', 'index': 7, 'shape': array([ 1,  3,  3, 32], dtype=int32), 'shape_signature': array([ 1,  3,  3, 32], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'model_1/re_lu_2/Relu;model_1/batch_normalization_2/FusedBatchNormV3;model_1/conv2d_1/BiasAdd/ReadVariableOp;model_1/conv2d_1/BiasAdd;model_1/depthwise_conv2d_1/depthwise;model_1/conv2d_1/Conv2D', 'index': 8, 'shape': array([64], dtype=int32), 'shape_signature': array([64], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'model_1/batch_normalization_3/FusedBatchNormV3;model_1/depthwise_conv2d_1/depthwise;model_1/depthwise_conv2d_1/BiasAdd/ReadVariableOp;model_1/depthwise_conv2d_1/BiasAdd', 'index': 9, 'shape': array([ 1,  3,  3, 64], dtype=int32), 'shape_signature': array([ 1,  3,  3, 64], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'model_1/re_lu_4/Relu;model_1/batch_normalization_4/FusedBatchNormV3;model_1/conv2d_2/BiasAdd/ReadVariableOp;model_1/conv2d_2/BiasAdd;model_1/depthwise_conv2d_2/depthwise;model_1/conv2d_2/Conv2D', 'index': 10, 'shape': array([128], dtype=int32), 'shape_signature': array([128], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'model_1/batch_normalization_5/FusedBatchNormV3;model_1/depthwise_conv2d_2/depthwise;model_1/depthwise_conv2d_2/BiasAdd/ReadVariableOp;model_1/depthwise_conv2d_2/BiasAdd', 'index': 11, 'shape': array([  1,   3,   3, 128], dtype=int32), 'shape_signature': array([  1,   3,   3, 128], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'model_1/re_lu_6/Relu;model_1/batch_normalization_6/FusedBatchNormV3;model_1/conv2d_3/BiasAdd/ReadVariableOp;model_1/conv2d_3/BiasAdd;model_1/depthwise_conv2d_4/depthwise;model_1/conv2d_3/Conv2D', 'index': 12, 'shape': array([256], dtype=int32), 'shape_signature': array([256], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'model_1/batch_normalization_7/FusedBatchNormV3;model_1/depthwise_conv2d_3/depthwise;model_1/depthwise_conv2d_3/BiasAdd/ReadVariableOp;model_1/depthwise_conv2d_3/BiasAdd;model_1/depthwise_conv2d_4/depthwise', 'index': 13, 'shape': array([  1,   3,   3, 256], dtype=int32), 'shape_signature': array([  1,   3,   3, 256], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'model_1/re_lu_8/Relu;model_1/batch_normalization_8/FusedBatchNormV3;model_1/conv2d_4/BiasAdd/ReadVariableOp;model_1/conv2d_4/BiasAdd;model_1/depthwise_conv2d_4/depthwise;model_1/conv2d_4/Conv2D', 'index': 14, 'shape': array([256], dtype=int32), 'shape_signature': array([256], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'model_1/batch_normalization_9/FusedBatchNormV3;model_1/depthwise_conv2d_4/depthwise;model_1/depthwise_conv2d_4/BiasAdd/ReadVariableOp;model_1/depthwise_conv2d_4/BiasAdd', 'index': 15, 'shape': array([  1,   3,   3, 256], dtype=int32), 'shape_signature': array([  1,   3,   3, 256], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'model_1/re_lu_10/Relu;model_1/batch_normalization_10/FusedBatchNormV3;model_1/conv2d_5/BiasAdd/ReadVariableOp;model_1/conv2d_5/BiasAdd;model_1/conv2d_5/Conv2D', 'index': 16, 'shape': array([512], dtype=int32), 'shape_signature': array([512], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'model_1/conv2d/Conv2D', 'index': 17, 'shape': array([32,  3,  3,  1], dtype=int32), 'shape_signature': array([32,  3,  3,  1], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'model_1/conv2d_1/Conv2D', 'index': 18, 'shape': array([64,  1,  1, 32], dtype=int32), 'shape_signature': array([64,  1,  1, 32], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'model_1/conv2d_2/Conv2D', 'index': 19, 'shape': array([128,   1,   1,  64], dtype=int32), 'shape_signature': array([128,   1,   1,  64], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'model_1/conv2d_3/Conv2D', 'index': 20, 'shape': array([256,   1,   1, 128], dtype=int32), 'shape_signature': array([256,   1,   1, 128], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'model_1/conv2d_4/Conv2D', 'index': 21, 'shape': array([256,   1,   1, 256], dtype=int32), 'shape_signature': array([256,   1,   1, 256], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'model_1/conv2d_5/Conv2D', 'index': 22, 'shape': array([512,   1,   1, 256], dtype=int32), 'shape_signature': array([512,   1,   1, 256], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'model_1/dense_1/BiasAdd/ReadVariableOp', 'index': 23, 'shape': array([1], dtype=int32), 'shape_signature': array([1], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'model_1/global_average_pooling2d_1/Mean/reduction_indices', 'index': 24, 'shape': array([2], dtype=int32), 'shape_signature': array([2], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'model_1/dense_1/MatMul', 'index': 25, 'shape': array([  1, 512], dtype=int32), 'shape_signature': array([  1, 512], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'model_1/re_lu/Relu;model_1/batch_normalization/FusedBatchNormV3;model_1/conv2d/BiasAdd/ReadVariableOp;model_1/conv2d/BiasAdd;model_1/depthwise_conv2d/depthwise;model_1/conv2d/Conv2D1', 'index': 26, 'shape': array([  1, 128, 128,  32], dtype=int32), 'shape_signature': array([ -1, 128, 128,  32], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'model_1/re_lu_1/Relu;model_1/batch_normalization_1/FusedBatchNormV3;model_1/depthwise_conv2d/depthwise;model_1/depthwise_conv2d/BiasAdd/ReadVariableOp;model_1/depthwise_conv2d/BiasAdd1', 'index': 27, 'shape': array([  1, 128, 128,  32], dtype=int32), 'shape_signature': array([ -1, 128, 128,  32], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'model_1/re_lu_2/Relu;model_1/batch_normalization_2/FusedBatchNormV3;model_1/conv2d_1/BiasAdd/ReadVariableOp;model_1/conv2d_1/BiasAdd;model_1/depthwise_conv2d_1/depthwise;model_1/conv2d_1/Conv2D1', 'index': 28, 'shape': array([  1, 128, 128,  64], dtype=int32), 'shape_signature': array([ -1, 128, 128,  64], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'model_1/re_lu_3/Relu;model_1/batch_normalization_3/FusedBatchNormV3;model_1/depthwise_conv2d_1/depthwise;model_1/depthwise_conv2d_1/BiasAdd/ReadVariableOp;model_1/depthwise_conv2d_1/BiasAdd1', 'index': 29, 'shape': array([ 1, 64, 64, 64], dtype=int32), 'shape_signature': array([-1, 64, 64, 64], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'model_1/re_lu_4/Relu;model_1/batch_normalization_4/FusedBatchNormV3;model_1/conv2d_2/BiasAdd/ReadVariableOp;model_1/conv2d_2/BiasAdd;model_1/depthwise_conv2d_2/depthwise;model_1/conv2d_2/Conv2D1', 'index': 30, 'shape': array([  1,  64,  64, 128], dtype=int32), 'shape_signature': array([ -1,  64,  64, 128], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'model_1/re_lu_5/Relu;model_1/batch_normalization_5/FusedBatchNormV3;model_1/depthwise_conv2d_2/depthwise;model_1/depthwise_conv2d_2/BiasAdd/ReadVariableOp;model_1/depthwise_conv2d_2/BiasAdd1', 'index': 31, 'shape': array([  1,  32,  32, 128], dtype=int32), 'shape_signature': array([ -1,  32,  32, 128], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'model_1/re_lu_6/Relu;model_1/batch_normalization_6/FusedBatchNormV3;model_1/conv2d_3/BiasAdd/ReadVariableOp;model_1/conv2d_3/BiasAdd;model_1/depthwise_conv2d_4/depthwise;model_1/conv2d_3/Conv2D1', 'index': 32, 'shape': array([  1,  32,  32, 256], dtype=int32), 'shape_signature': array([ -1,  32,  32, 256], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'model_1/re_lu_7/Relu;model_1/batch_normalization_7/FusedBatchNormV3;model_1/depthwise_conv2d_3/depthwise;model_1/depthwise_conv2d_3/BiasAdd/ReadVariableOp;model_1/depthwise_conv2d_3/BiasAdd;model_1/depthwise_conv2d_4/depthwise1', 'index': 33, 'shape': array([  1,  32,  32, 256], dtype=int32), 'shape_signature': array([ -1,  32,  32, 256], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'model_1/re_lu_8/Relu;model_1/batch_normalization_8/FusedBatchNormV3;model_1/conv2d_4/BiasAdd/ReadVariableOp;model_1/conv2d_4/BiasAdd;model_1/depthwise_conv2d_4/depthwise;model_1/conv2d_4/Conv2D1', 'index': 34, 'shape': array([  1,  32,  32, 256], dtype=int32), 'shape_signature': array([ -1,  32,  32, 256], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'model_1/re_lu_9/Relu;model_1/batch_normalization_9/FusedBatchNormV3;model_1/depthwise_conv2d_4/depthwise;model_1/depthwise_conv2d_4/BiasAdd/ReadVariableOp;model_1/depthwise_conv2d_4/BiasAdd1', 'index': 35, 'shape': array([  1,  32,  32, 256], dtype=int32), 'shape_signature': array([ -1,  32,  32, 256], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'model_1/re_lu_10/Relu;model_1/batch_normalization_10/FusedBatchNormV3;model_1/conv2d_5/BiasAdd/ReadVariableOp;model_1/conv2d_5/BiasAdd;model_1/conv2d_5/Conv2D1', 'index': 36, 'shape': array([  1,  32,  32, 512], dtype=int32), 'shape_signature': array([ -1,  32,  32, 512], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'model_1/global_average_pooling2d_1/Mean', 'index': 37, 'shape': array([  1, 512], dtype=int32), 'shape_signature': array([ -1, 512], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'model_1/dense_1/MatMul;model_1/dense_1/BiasAdd', 'index': 38, 'shape': array([1, 1], dtype=int32), 'shape_signature': array([-1,  1], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:0', 'index': 39, 'shape': array([1, 1], dtype=int32), 'shape_signature': array([-1,  1], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=\"person_detection.tflite\")\n",
    "# Get input and output tensors.\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "print(input_details, output_details)\n",
    "print(\"tensor details\")\n",
    "print(interpreter.get_tensor_details())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Check inference difference between TFLITE, TFLITE quantized and original TF model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "def get_prediction_from_tflite(interpreter, input):\n",
    "    interpreter.allocate_tensors()\n",
    "    input_details = interpreter.get_input_details()\n",
    "    interpreter.set_tensor(input_details[0]['index'], input)\n",
    "    output_details = interpreter.get_output_details()\n",
    "    interpreter.invoke()\n",
    "    return interpreter.get_tensor(output_details[0]['index'])[0]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 125ms/step\n",
      "[0.7237123] [0.7109375] [0.72371197]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[0.9737151] [0.96875] [0.9737151]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "[0.9739039] [0.97265625] [0.9739038]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[0.9744072] [0.96875] [0.97440726]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "[0.9995046] [0.99609375] [0.9995046]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "[0.92357093] [0.890625] [0.92357093]\n"
     ]
    }
   ],
   "source": [
    "for image in load_grayscale_images(limit=5):\n",
    "    image = image[0]\n",
    "    prediction_from_tflite = get_prediction_from_tflite(interpreter, image)\n",
    "    prediction_from_tflite_quant = get_prediction_from_tflite(interpreter_quant, image)\n",
    "    prediction_from_tf = model_fitted.predict(image)[0]\n",
    "    print(prediction_from_tflite, prediction_from_tflite_quant, prediction_from_tf)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "### Transform it into char array"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "! xxd -i person_detection_quantized.tflite > esp32_model.cc\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "env",
   "language": "python",
   "display_name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
