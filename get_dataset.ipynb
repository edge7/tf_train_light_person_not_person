{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "from pycocotools.coco import COCO\n",
    "import urllib\n",
    "import csv\n",
    "from tqdm import tqdm\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "DATA_ROOT_FOLDER = \"/media/edge7/TOSHIBA EXT/\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Get COCO annotation file, plus IMDb-face CSV (they are 2 well-known datasets)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-03-10 13:07:49--  http://images.cocodataset.org/annotations/annotations_trainval2017.zip\r\n",
      "Resolving images.cocodataset.org (images.cocodataset.org)... 3.5.27.112, 54.231.199.97, 52.216.245.244, ...\r\n",
      "Connecting to images.cocodataset.org (images.cocodataset.org)|3.5.27.112|:80... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 252907541 (241M) [application/zip]\r\n",
      "Saving to: ‘annotations_trainval2017.zip’\r\n",
      "\r\n",
      "annotations_trainva 100%[===================>] 241.19M  27.9MB/s    in 9.3s    \r\n",
      "\r\n",
      "2023-03-10 13:07:58 (26.1 MB/s) - ‘annotations_trainval2017.zip’ saved [252907541/252907541]\r\n",
      "\r\n",
      "Archive:  annotations_trainval2017.zip\r\n",
      "  inflating: annotations/instances_train2017.json  \r\n",
      "  inflating: annotations/instances_val2017.json  \r\n",
      "  inflating: annotations/captions_train2017.json  \r\n",
      "  inflating: annotations/captions_val2017.json  \r\n",
      "  inflating: annotations/person_keypoints_train2017.json  \r\n",
      "  inflating: annotations/person_keypoints_val2017.json  \r\n",
      "--2023-03-10 13:08:03--  https://storage.googleapis.com/public_stuff/IMDb-Face.csv\r\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 142.251.209.48, 142.250.184.80, 142.250.184.112, ...\r\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|142.251.209.48|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 291641388 (278M) [text/csv]\r\n",
      "Saving to: ‘IMDb-Face.csv’\r\n",
      "\r\n",
      "IMDb-Face.csv       100%[===================>] 278.13M  43.1MB/s    in 12s     \r\n",
      "\r\n",
      "2023-03-10 13:08:15 (22.9 MB/s) - ‘IMDb-Face.csv’ saved [291641388/291641388]\r\n",
      "\r\n",
      "Creating layout folder in /media/edge7/TOSHIBA EXT/\r\n",
      "done\r\n"
     ]
    }
   ],
   "source": [
    "!bash get_annotations.sh \"{DATA_ROOT_FOLDER}\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Set Number of Images, feel free to change the below"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "N_PERSON_TOTAL = 10000 # Modify this, as you want\n",
    "N_PERSON_COCO = int(N_PERSON_TOTAL * 0.3)\n",
    "N_PERSON_IMDB = N_PERSON_TOTAL - N_PERSON_COCO\n",
    "N_NOT_PERSON_TOTAL = N_PERSON_TOTAL # Modify this if you don't want a balanced dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.39s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "coco=COCO('annotations/instances_val2017.json')\n",
    "catIds = coco.getCatIds(catNms=['person'])\n",
    "imgIds = coco.getImgIds(catIds=catIds)\n",
    "img_infos = coco.loadImgs(imgIds)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 2693/3000 [26:47<03:03,  1.68it/s]\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "with tqdm(total=N_PERSON_COCO) as pbar:\n",
    "    for img_info in img_infos:\n",
    "        img_url = img_info['coco_url']\n",
    "        img_filename = f\"{DATA_ROOT_FOLDER}/data/person/{img_info['file_name']}\"\n",
    "        urllib.request.urlretrieve(img_url, img_filename)\n",
    "        counter +=1\n",
    "        pbar.update(1)\n",
    "        if counter == N_PERSON_COCO:\n",
    "         break"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Now get the remaining from the IMDb-face dataset, the file should have been automatically downloaded"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7000/7000 [46:59<00:00,  2.48it/s]  \n"
     ]
    }
   ],
   "source": [
    "from urllib.error import HTTPError\n",
    "import random\n",
    "seed_value = 1234\n",
    "random.seed(seed_value)\n",
    "\n",
    "counter = 0\n",
    "with open('IMDb-Face.csv', newline='') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    with tqdm(total=N_PERSON_IMDB) as pbar:\n",
    "        for row in reader:\n",
    "            if counter == N_PERSON_IMDB:\n",
    "                break\n",
    "            if random.random() < 0.2: # to avoid to take the same person too many times\n",
    "                img_filename = f\"{DATA_ROOT_FOLDER}/data/person/IMDB_{counter}_{row['image']}\"\n",
    "                try:\n",
    "                    urllib.request.urlretrieve(row['url'], img_filename)\n",
    "                    counter +=1\n",
    "                    pbar.update(1)\n",
    "                except HTTPError as e:\n",
    "                    pass #  Some images are not available, just skip\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 3760/10033 [36:55<57:13,  1.83it/s]  "
     ]
    }
   ],
   "source": [
    "catIds = coco.getCatIds()\n",
    "catIds.remove(coco.getCatIds(catNms=['person'])[0])\n",
    "N = int(N_NOT_PERSON_TOTAL / len(catIds)) +1\n",
    "\n",
    "# get image IDs for all categories except 'person'\n",
    "imgIds = []\n",
    "for catId in catIds:\n",
    "    imgIds.append((coco.loadCats(catId)[0]['name'], coco.getImgIds(catIds=[catId])))\n",
    "\n",
    "\n",
    "# download the images\n",
    "with tqdm(total=N * len(catIds)) as pbar:\n",
    "    for cat, imgs in imgIds:\n",
    "        imgs = coco.loadImgs(imgs)\n",
    "        COUNTER_PER_CATEGORY = 0\n",
    "        for img_info in imgs:\n",
    "            img_url = img_info['coco_url']\n",
    "            img_filename = f\"{DATA_ROOT_FOLDER}/data/notperson/{cat}_{img_info['file_name']}\"\n",
    "            # load the annotations for the image\n",
    "            annIds = coco.getAnnIds(imgIds=img_info['id'])\n",
    "            anns = coco.loadAnns(annIds)\n",
    "            if not any([ann['category_id'] == 1 for ann in anns]): # be 101% sure no person is in the image\n",
    "                pbar.update(1)\n",
    "                try:\n",
    "                    urllib.request.urlretrieve(img_url, img_filename)\n",
    "                    COUNTER_PER_CATEGORY +=1\n",
    "                except Exception as e:\n",
    "                    pass\n",
    "                if COUNTER_PER_CATEGORY == N:\n",
    "                    break\n",
    "\n",
    "print(\"DONE!\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"All done dataset ready for training\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "env",
   "language": "python",
   "display_name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
